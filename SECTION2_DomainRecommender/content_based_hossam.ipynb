{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Content-Based Recommendation\n",
                "\n",
                "## 3. Feature Extraction and Vector Space Model\n",
                "\n",
                "In this section, we implement **Text Feature Extraction** using a manually constructed **TF-IDF (Term Frequency-Inverse Document Frequency)** vectorizer. \n",
                "\n",
                "We will not use high-level libraries like `sklearn`'s `TfidfVectorizer` for the core logic. instead, we will build the process step-by-step:\n",
                "1.  **Text Preprocessing**: Tokenization and stop-word removal.\n",
                "2.  **Vocabulary Building**: Identifying unique terms and their document frequencies.\n",
                "3.  **IDF Computation**: Calculating the inverse document frequency weights.\n",
                "4.  **Vector Construction**: Transforming text data into a sparse TF-IDF matrix.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "23952c61",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import re\n",
                "import math\n",
                "from collections import Counter\n",
                "from scipy.sparse import csr_matrix, hstack, save_npz, vstack, diags\n",
                "import os\n",
                "\n",
                "# Ensure results directory exists\n",
                "RESULTS_DIR = \"../results\"\n",
                "if not os.path.exists(RESULTS_DIR):\n",
                "    os.makedirs(RESULTS_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "afd771cb",
            "metadata": {},
            "source": [
                "### Subtask 1: Define the text source for items\n",
                "\n",
                "We will extract the relevant text data from our items. We will combine `title` and `categories` into a single text string for each item."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de925394",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_item_text_data(df_items):\n",
                "    \"\"\"\n",
                "    Extracts and combines title and categories into a single text field.\n",
                "    Expects a DataFrame unique by item_id.\n",
                "    \"\"\"\n",
                "    print(\"Extracting item text data...\")\n",
                "    \n",
                "    # Ensure we are working with string types\n",
                "    df_items['title'] = df_items['title'].fillna('')\n",
                "    df_items['categories'] = df_items['categories'].fillna('')\n",
                "    \n",
                "    # Combine title and categories\n",
                "    # Helper to clean category string representation if it looks like \"['Books', 'Fiction']\"\n",
                "    def clean_cat(c):\n",
                "        if isinstance(c, str) and c.startswith(\"[\") and c.endswith(\"]\"):\n",
                "             # Simple parse or just strip\n",
                "             return c.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \" \")\n",
                "        return str(c)\n",
                "\n",
                "    df_items['text_source'] = df_items['title'] + \" \" + df_items['categories'].apply(clean_cat)\n",
                "    \n",
                "    print(f\"Created text corpus for {len(df_items)} items.\")\n",
                "    return df_items['text_source'].tolist(), df_items['item_id'].tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cf27aed1",
            "metadata": {},
            "source": [
                "### Subtask 2: Basic text preprocessing\n",
                "\n",
                "We perform tokenization (splitting text into words) and remove common stop-words."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "079df565",
            "metadata": {},
            "outputs": [],
            "source": [
                "def manual_tokenize_and_clean(text_corpus):\n",
                "    \"\"\"\n",
                "    Tokenizes text and removes stop words manually.\n",
                "    Returns a list of lists of tokens.\n",
                "    \"\"\"\n",
                "    print(\"Preprocessing text (Tokenization & Stop-word removal)...\")\n",
                "    \n",
                "    # Basic English Stop Words Set\n",
                "    STOP_WORDS = set([\n",
                "        'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
                "        'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
                "        'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
                "        'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
                "        'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
                "        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
                "        'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
                "        'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
                "        'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
                "        'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
                "        'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
                "        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '&'\n",
                "    ])\n",
                "    \n",
                "    processed_corpus = []\n",
                "    \n",
                "    for text in text_corpus:\n",
                "        # 1. Lowercase\n",
                "        text = text.lower()\n",
                "        # 2. Tokenize using regex (keep only alphanumeric)\n",
                "        tokens = re.findall(r'\\b[a-z]{2,}\\b', text)\n",
                "        # 3. Remove stop words\n",
                "        clean_tokens = [t for t in tokens if t not in STOP_WORDS]\n",
                "        processed_corpus.append(clean_tokens)\n",
                "        \n",
                "    print(f\"Preprocessed {len(processed_corpus)} documents.\")\n",
                "    return processed_corpus"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dbfa5858",
            "metadata": {},
            "source": [
                "### Subtask 3 & 4: Configure and Fit TF-IDF Vectorizer\n",
                "\n",
                "We will build the vocabulary from our processed corpus, filtering rare words to keep dimensionality manageable. Then, we calculate the IDF for each word.\n",
                "\n",
                "$$ IDF(t) = \\log \\left( \\frac{N}{DF(t)} \\right) $$\n",
                "where $N$ is total documents and $DF(t)$ is document frequency of term $t$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f61ec43f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_vocabulary_and_idf(processed_corpus, min_df=5):\n",
                "    \"\"\"\n",
                "    Builds vocabulary and calculates IDF scores.\n",
                "    min_df: Ignore terms that appear in less than `min_df` documents.\n",
                "    \"\"\"\n",
                "    print(f\"Building vocabulary (min_df={min_df})...\")\n",
                "    \n",
                "    # 1. Calculate Document Frequencies (DF)\n",
                "    doc_freqs = Counter()\n",
                "    N = len(processed_corpus)\n",
                "    \n",
                "    for tokens in processed_corpus:\n",
                "        unique_tokens = set(tokens)\n",
                "        for t in unique_tokens:\n",
                "            doc_freqs[t] += 1\n",
                "            \n",
                "    total_unique_terms = len(doc_freqs)\n",
                "    \n",
                "    # 2. Filter by min_df and build Vocab Index\n",
                "    vocab = {}\n",
                "    idf_scores = {}\n",
                "    idx = 0\n",
                "    \n",
                "    sorted_terms = sorted(doc_freqs.keys()) \n",
                "    \n",
                "    for term in sorted_terms:\n",
                "        df = doc_freqs[term]\n",
                "        if df >= min_df:\n",
                "            vocab[term] = idx\n",
                "            # Standard IDF: log(N / df) + 1 (smoothing)\n",
                "            idf_scores[term] = math.log((N + 1) / (df + 1)) + 1\n",
                "            idx += 1\n",
                "            \n",
                "    print(f\"Validation: Processed {N} documents. Found {total_unique_terms} unique terms. \"\n",
                "          f\"Kept {len(vocab)} terms with frequency >= {min_df}.\")\n",
                "    return vocab, idf_scores"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d2a38163",
            "metadata": {},
            "source": [
                "### Subtask 4 (Continued): Transform to TF-IDF Matrix\n",
                "\n",
                "We now calculate the TF-IDF vector for each document and store it in a sparse CSR matrix.\n",
                "$$ TF\\hbox{-}IDF(t, d) = TF(t, d) \\times IDF(t) $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "675ece1f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_tf_idf_matrix(processed_corpus, vocab, idf_scores):\n",
                "    \"\"\"\n",
                "    Converts the corpus into a sparse TF-IDF matrix.\n",
                "    \"\"\"\n",
                "    print(\"Computing TF-IDF matrix...\")\n",
                "    rows = []\n",
                "    cols = []\n",
                "    data = []\n",
                "    \n",
                "    for doc_idx, tokens in enumerate(processed_corpus):\n",
                "        term_counts = Counter(tokens)\n",
                "        for term, count in term_counts.items():\n",
                "            if term in vocab:\n",
                "                col_idx = vocab[term]\n",
                "                tf_idf_val = count * idf_scores[term]\n",
                "                rows.append(doc_idx)\n",
                "                cols.append(col_idx)\n",
                "                data.append(tf_idf_val)\n",
                "\n",
                "    matrix = csr_matrix((data, (rows, cols)), shape=(len(processed_corpus), len(vocab)))\n",
                "    \n",
                "    print(\"Performing L2 Normalization...\")\n",
                "    row_sums = np.array(matrix.power(2).sum(axis=1))\n",
                "    row_norms = np.sqrt(row_sums)\n",
                "    row_norms[row_norms == 0] = 1.0 \n",
                "    row_norms = row_norms.flatten()\n",
                "    \n",
                "    inv_norms = 1.0 / row_norms\n",
                "    from scipy.sparse import diags\n",
                "    norm_matrix = diags(inv_norms) @ matrix\n",
                "    \n",
                "    print(f\"TF-IDF matrix computation complete. Shape: {norm_matrix.shape}\")\n",
                "    first_row_norm = np.sqrt(np.sum(norm_matrix[0].data**2)) if norm_matrix.shape[0] > 0 else 0\n",
                "    print(f\"Validation: L2 norm of the first document vector: {first_row_norm:.4f}\")\n",
                "    \n",
                "    return norm_matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff1e431e",
            "metadata": {},
            "source": [
                "### Subtask 5 & 6: Inspect and Validate\n",
                "\n",
                "We check the sparsity of our matrix and save a summary of the vocabulary to the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c40bfbe4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_and_save_features(matrix, vocab, item_ids):\n",
                "    \"\"\"\n",
                "    Validates the feature matrix and saves vocab summary.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Feature Space Validation ---\")\n",
                "    n_docs, n_terms = matrix.shape\n",
                "    nnz = matrix.nnz\n",
                "    sparsity = 1.0 - (nnz / (n_docs * n_terms))\n",
                "    \n",
                "    print(f\"Matrix Shape: ({n_docs}, {n_terms})\")\n",
                "    print(f\"Non-zero elements: {nnz})\")\n",
                "    print(f\"Sparsity: {sparsity*100:.4f}%\")\n",
                "    \n",
                "    # Save Vocabulary Summary\n",
                "    vocab_list = sorted(vocab.items(), key=lambda x: x[1])\n",
                "    df_vocab = pd.DataFrame(vocab_list, columns=['Term', 'Index'])\n",
                "    \n",
                "    full_vocab_path = os.path.join(RESULTS_DIR, \"tfidf_vocabulary_full.csv\")\n",
                "    sample_vocab_path = os.path.join(RESULTS_DIR, \"tfidf_vocabulary_sample.csv\")\n",
                "    \n",
                "    df_vocab.to_csv(full_vocab_path, index=False)\n",
                "    df_vocab.head(100).to_csv(sample_vocab_path, index=False)\n",
                "    \n",
                "    print(f\"Saved full vocabulary to {full_vocab_path}\")\n",
                "    print(f\"Saved top 100 vocabulary terms to {sample_vocab_path}\")\n",
                "    \n",
                "    return df_vocab"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99050dcc",
            "metadata": {},
            "source": [
                "## 3.2. Additional Features\n",
                "\n",
                "We incorporate **numerical features** (`price`, `average_rating`) and **categorical features** (`categories`) to enrich the item representation.\n",
                "\n",
                "### Subtask 1: Identify available additional features\n",
                "We extract `price` and `average_rating` from the metadata. `price` often requires cleaning (removing '$', converting to float)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "785cff9f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_additional_features(df_items):\n",
                "    \"\"\"\n",
                "    Extracts price and average_rating. \n",
                "    Expects df_items to have these columns. If not, we fill with defaults.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Extracting Additional Features ---\")\n",
                "    \n",
                "    # Create a copy to avoid SettingWithCopy warnings on the main df\n",
                "    df_features = df_items.copy()\n",
                "    \n",
                "    # Check if columns exist, otherwise create them with NaNs\n",
                "    if 'price' not in df_features.columns:\n",
                "        df_features['price'] = np.nan\n",
                "    if 'average_rating' not in df_features.columns:\n",
                "        df_features['average_rating'] = np.nan\n",
                "        \n",
                "    # Clean Price\n",
                "    def clean_price(p):\n",
                "        if isinstance(p, (int, float)):\n",
                "            return float(p)\n",
                "        if isinstance(p, str):\n",
                "            match = re.search(r'(\\d+\\.?\\d*)', p)\n",
                "            if match:\n",
                "                return float(match.group(1))\n",
                "        return np.nan\n",
                "\n",
                "    df_features['price_num'] = df_features['price'].apply(clean_price)\n",
                "    \n",
                "    # Clean Rating\n",
                "    def clean_rating(r):\n",
                "        try:\n",
                "            return float(r)\n",
                "        except:\n",
                "            return np.nan\n",
                "            \n",
                "    df_features['rating_num'] = df_features['average_rating'].apply(clean_rating)\n",
                "    \n",
                "    # Impute missing values with median (Manual Imputation)\n",
                "    price_median = df_features['price_num'].median()\n",
                "    rating_median = df_features['rating_num'].median()\n",
                "    \n",
                "    if pd.isna(price_median): price_median = 0.0\n",
                "    if pd.isna(rating_median): rating_median = 3.0 \n",
                "    \n",
                "    df_features['price_num'] = df_features['price_num'].fillna(price_median)\n",
                "    df_features['rating_num'] = df_features['rating_num'].fillna(rating_median)\n",
                "    \n",
                "    print(f\"Extracted numerical features. Imputed Price Median: {price_median}, Rating Median: {rating_median}\")\n",
                "    return df_features[['item_id', 'price_num', 'rating_num', 'categories']]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "187b76b5",
            "metadata": {},
            "source": [
                "### Subtask 2-4: Process features\n",
                "\n",
                "**1. Numerical Features**: We normalize `price` and `rating` using **Min-Max Scaling** manually to bring them to [0, 1] range.\n",
                "\n",
                "**2. Categorical Features**: We perform a simplified **One-Hot Encoding** for the top `K` most frequent categories."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "301c0bb1",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_numerical_features(df_features):\n",
                "    \"\"\"\n",
                "    Normalizes numerical columns using Min-Max scaling manually.\n",
                "    \"\"\"\n",
                "    print(\"Processing numerical features (Min-Max Scaling)...\")\n",
                "    \n",
                "    # Price\n",
                "    p_min = df_features['price_num'].min()\n",
                "    p_max = df_features['price_num'].max()\n",
                "    if p_max > p_min:\n",
                "        df_features['price_scaled'] = (df_features['price_num'] - p_min) / (p_max - p_min)\n",
                "    else:\n",
                "        df_features['price_scaled'] = 0.0\n",
                "        \n",
                "    # Rating\n",
                "    r_min = df_features['rating_num'].min()\n",
                "    r_max = df_features['rating_num'].max()\n",
                "    if r_max > r_min:\n",
                "        df_features['rating_scaled'] = (df_features['rating_num'] - r_min) / (r_max - r_min)\n",
                "    else:\n",
                "        df_features['rating_scaled'] = 0.5\n",
                "        \n",
                "    return df_features[['price_scaled', 'rating_scaled']].values\n",
                "\n",
                "def process_categorical_features(df_features, top_k=20):\n",
                "    \"\"\"\n",
                "    Manually One-Hot Encodes top K categories.\n",
                "    \"\"\"\n",
                "    print(f\"Processing categorical features (Top {top_k} OHE)...\")\n",
                "    \n",
                "    all_cats = []\n",
                "    cat_series = df_features['categories'].astype(str)\n",
                "    \n",
                "    for entry in cat_series:\n",
                "        clean = re.sub(r'[^a-zA-Z0-9\\s]', ' ', entry)\n",
                "        words = clean.split()\n",
                "        all_cats.extend(words)\n",
                "        \n",
                "    cat_counts = Counter(all_cats)\n",
                "    top_cats = [c[0] for c in cat_counts.most_common(top_k) if len(c[0]) > 2]\n",
                "    top_cats = top_cats[:top_k]\n",
                "    \n",
                "    print(f\"Top categories identified: {top_cats}\")\n",
                "    \n",
                "    N = len(df_features)\n",
                "    cat_matrix = np.zeros((N, len(top_cats)))\n",
                "    \n",
                "    for i, entry in enumerate(cat_series):\n",
                "        entry_lower = entry.lower()\n",
                "        for j, cat in enumerate(top_cats):\n",
                "            if cat.lower() in entry_lower:\n",
                "                cat_matrix[i, j] = 1.0\n",
                "                \n",
                "    return cat_matrix, top_cats"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c0abb9d8",
            "metadata": {},
            "source": [
                "### Subtask 5: Combine features\n",
                "\n",
                "We concatenate the sparse TF-IDF matrix with the dense numerical and categorical matrices."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d835c3c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def combine_features(tfidf_matrix, num_features, cat_features):\n",
                "    \"\"\"\n",
                "    Combines TF-IDF, Numerical, and Categorical features.\n",
                "    \"\"\"\n",
                "    print(\"Combining all features...\")\n",
                "    \n",
                "    num_sparse = csr_matrix(num_features)\n",
                "    cat_sparse = csr_matrix(cat_features)\n",
                "    \n",
                "    final_matrix = hstack([tfidf_matrix, num_sparse, cat_sparse], format='csr')\n",
                "    \n",
                "    print(f\"Final Feature Matrix Shape: {final_matrix.shape}\")\n",
                "    \n",
                "    # Save matrix\n",
                "    save_npz_path = os.path.join(RESULTS_DIR, \"feature_matrix.npz\")\n",
                "    save_npz(save_npz_path, final_matrix)\n",
                "    print(f\"Feature matrix saved to {save_npz_path}\")\n",
                "    \n",
                "    return final_matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ea8e1e0f",
            "metadata": {},
            "source": [
                "## 3.3. Create item-feature matrix and document your feature selection\n",
                "\n",
                "We have combined the features. Now we must **validate** the consistency of the feature space and **document** our rationale.\n",
                "\n",
                "### Subtask 5 & 6: Validate and Check Scaling\n",
                "We check if the different feature distincts (TF-IDF vs Numerical) have vastly different magnitudes. While TF-IDF is unit-length (L2), numerical features are [0, 1]. In high dimensions, unit vectors have small components. We verify statistics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "00e62610",
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_item_feature_matrix(matrix):\n",
                "    \"\"\"\n",
                "    Checks the final matrix properties and scaling consistency.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Validating Item-Feature Matrix ---\")\n",
                "    \n",
                "    # 1. Shape and Sparsity\n",
                "    n_items, n_features = matrix.shape\n",
                "    nnz = matrix.nnz\n",
                "    sparsity = 1.0 - (nnz / (n_items * n_features))\n",
                "    print(f\"Final Matrix Shape: ({n_items}, {n_features})\")\n",
                "    print(f\"Sparsity: {sparsity*100:.4f}%\")\n",
                "    \n",
                "    # 2. Statistics of Values (Random Sample of rows)\n",
                "    # We want to see max values in the matrix to ensure nothing explodes\n",
                "    sample_indices = np.random.choice(n_items, size=min(1000, n_items), replace=False)\n",
                "    sample_matrix = matrix[sample_indices]\n",
                "    \n",
                "    max_val = sample_matrix.max()\n",
                "    mean_val = sample_matrix.mean()\n",
                "    \n",
                "    print(f\"Max value in sample: {max_val:.4f}\")\n",
                "    print(f\"Mean value in sample: {mean_val:.6f} (Expected to be low due to sparsity)\")\n",
                "    \n",
                "    # 3. Check Row Norms (Are they roughly consistent?)\n",
                "    # TF-IDF rows are norm 1. Adding [0,1] features will increase norm > 1.\n",
                "    row_sums = np.array(sample_matrix.power(2).sum(axis=1))\n",
                "    row_norms = np.sqrt(row_sums).flatten()\n",
                "    \n",
                "    print(f\"Average Row L2 Norm: {np.mean(row_norms):.4f} (TF-IDF base was 1.0)\")\n",
                "    \n",
                "    if max_val > 10.0:\n",
                "        print(\"WARNING: Some features have very high values. scaling might be off.\")\n",
                "    else:\n",
                "        print(\"Scaling consistency check passed (Values roughly in expected range).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e886715e",
            "metadata": {},
            "source": [
                "### Subtask 7: Document feature selection rationale\n",
                "\n",
                "We save a explanation of why we chose these features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2112afa3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_feature_selection_rationale():\n",
                "    \"\"\"\n",
                "    Saves the feature selection rationale.\n",
                "    \"\"\"\n",
                "    print(\"Saving feature selection rationale...\")\n",
                "    \n",
                "    rationale = \"\"\"\n",
                "# Feature Selection Rationale for Book Recommendation\n",
                "\n",
                "## 1. Text Features (TF-IDF)\n",
                "- **Source**: 'title' combined with 'categories'.\n",
                "- **Method**: TF-IDF (Term Frequency-Inverse Document Frequency).\n",
                "- **Reason**: Books are content-rich items. Title and categories provide strong semantic signals about the book's topic/genre. TF-IDF downweights common words ensuring unique keywords drive similarity.\n",
                "\n",
                "## 2. Numerical Features\n",
                "- **Features**: 'price', 'average_rating'.\n",
                "- **Method**: Min-Max Scaling [0, 1].\n",
                "- **Reason**: \n",
                "    - **Price**: Users often prefer books in specific price ranges. Normalization ensures it doesn't dominate the vector space.\n",
                "    - **Average Rating**: Acts as a proxy for quality. Higher rated items might be more 'summable' with other high quality items.\n",
                "\n",
                "## 3. Categorical Features\n",
                "- **Method**: One-Hot Encoding (Top 20 frequent categories).\n",
                "- **Reason**: While 'categories' are in the text indices, explicit dimensions for major genres (Fiction, Mystery, etc.) allow the model to strictly cluster items of the same 'type' even if titles are very different.\n",
                "\n",
                "## 4. Combination\n",
                "- We stack these vectors. The final representation mixes semantic similarity (Text) with property similarity (Price/Quality/Genre).\n",
                "\"\"\"\n",
                "    \n",
                "    path = os.path.join(RESULTS_DIR, \"feature_selection_rationale.md\")\n",
                "    with open(path, \"w\") as f:\n",
                "        f.write(rationale)\n",
                "        \n",
                "    print(f\"Rationale saved to {path}\")\n",
                "    \n",
                "    print(\"Feature Matrix Creation and Documentation Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2aa47267",
            "metadata": {},
            "source": [
                "# -------------------------------------------------------------------------\n",
                "# 4. User Profile Construction\n",
                "# -------------------------------------------------------------------------\n",
                "\n",
                "We construct user profiles by computing the **weighted average** of the feature vectors of items they have rated. \n",
                "\n",
                "### Subtask 1-4: Build Profiles (Batched)\n",
                "**Correction:** Due to large number of users, we process in batches and save intermediate sparse matrices to avoid memory errors.\n",
                "\n",
                "For each user $u$:\n",
                "$$ \\vec{p}_u = \\frac{\\sum_{i \\in I_u} r_{ui} \\cdot \\vec{f}_i}{\\sum_{i \\in I_u} r_{ui}} $$\n",
                "where $\\vec{f}_i$ is the item feature vector and $r_{ui}$ is the rating."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f2b6cb3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_user_profiles(df_interactions, item_feature_matrix, df_items_map, batch_size=5000):\n",
                "    \"\"\"\n",
                "    Constructs user profiles in batches to manage memory.\n",
                "    Saves chunks to results/user_profiles_parts/.\n",
                "    Returns a list of paths to the saved chunks.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- User Profile Construction (Batched) ---\")\n",
                "    \n",
                "    # Create parts directory\n",
                "    parts_dir = os.path.join(RESULTS_DIR, \"user_profiles_parts\")\n",
                "    if not os.path.exists(parts_dir):\n",
                "        os.makedirs(parts_dir)\n",
                "        \n",
                "    # 1. Map Item IDs -> Matrix Indices\n",
                "    print(\"Mapping item IDs to feature matrix indices...\")\n",
                "    item_to_idx = {iid: idx for idx, iid in enumerate(df_items_map['item_id'])}\n",
                "    \n",
                "    # 2. Group interactions\n",
                "    user_groups = df_interactions.groupby('user_id')\n",
                "    n_users = len(user_groups)\n",
                "    print(f\"Total users to process: {n_users}\")\n",
                "    \n",
                "    current_batch_vectors = []\n",
                "    current_batch_ids = []\n",
                "    saved_batches = []\n",
                "    \n",
                "    count = 0\n",
                "    n_features = item_feature_matrix.shape[1]\n",
                "    \n",
                "    for uid, group in user_groups:\n",
                "        valid_indices = []\n",
                "        ratings = []\n",
                "        \n",
                "        for _, row in group.iterrows():\n",
                "            iid = row['item_id']\n",
                "            r = row['rating']\n",
                "            if iid in item_to_idx:\n",
                "                valid_indices.append(item_to_idx[iid])\n",
                "                ratings.append(r)\n",
                "        \n",
                "        # Calculate User Vector\n",
                "        if not valid_indices:\n",
                "            # Cold start / No valid items -> Zero Vector\n",
                "            user_vec_sparse = csr_matrix((1, n_features))\n",
                "        else:\n",
                "            item_vecs = item_feature_matrix[valid_indices]\n",
                "            # Weighted Sum: sum(r_i * v_i)\n",
                "            # item_vecs is sparse. ratings is scalar list.\n",
                "            # multiply returns sparse. sum returns dense np.matrix.\n",
                "            ratings_arr = np.array(ratings).reshape(-1, 1)\n",
                "            weighted_sum_dense = item_vecs.multiply(ratings_arr).sum(axis=0)\n",
                "            \n",
                "            # Normalize by total rating spread\n",
                "            total_rating = np.sum(ratings)\n",
                "            if total_rating > 0:\n",
                "                weighted_sum_dense /= total_rating\n",
                "                \n",
                "            # CRITICAL: Convert back to sparse immediately to save memory\n",
                "            user_vec_sparse = csr_matrix(weighted_sum_dense)\n",
                "            \n",
                "        current_batch_vectors.append(user_vec_sparse)\n",
                "        current_batch_ids.append(uid)\n",
                "        count += 1\n",
                "        \n",
                "        # Batch Save Check\n",
                "        if len(current_batch_vectors) >= batch_size:\n",
                "            # Stack\n",
                "            batch_matrix = vstack(current_batch_vectors)\n",
                "            \n",
                "            # Normalize Batch (L2) - Optimization allows doing this on chunks\n",
                "            # Row norms\n",
                "            row_sums = np.array(batch_matrix.power(2).sum(axis=1))\n",
                "            row_norms = np.sqrt(row_sums).flatten()\n",
                "            row_norms[row_norms == 0] = 1.0\n",
                "            inv_norms = 1.0 / row_norms\n",
                "            batch_matrix = diags(inv_norms) @ batch_matrix\n",
                "            \n",
                "            # Save\n",
                "            batch_idx = len(saved_batches)\n",
                "            filename = f\"user_profiles_part_{batch_idx}.npz\"\n",
                "            path = os.path.join(parts_dir, filename)\n",
                "            save_npz(path, batch_matrix)\n",
                "            \n",
                "            # Save IDs\n",
                "            id_path = path.replace(\".npz\", \"_ids.csv\")\n",
                "            pd.DataFrame(current_batch_ids, columns=['user_id']).to_csv(id_path, index=False)\n",
                "            \n",
                "            saved_batches.append(path)\n",
                "            print(f\"Saved batch {batch_idx}: {batch_matrix.shape} to {filename}\")\n",
                "            \n",
                "            # Clear Memory\n",
                "            current_batch_vectors = []\n",
                "            current_batch_ids = []\n",
                "            import gc; gc.collect()\n",
                "            \n",
                "        if count % 10000 == 0:\n",
                "            print(f\"Processed {count}/{n_users} users...\")\n",
                "\n",
                "    # Process Final Batch\n",
                "    if current_batch_vectors:\n",
                "        batch_matrix = vstack(current_batch_vectors)\n",
                "        \n",
                "        # Normalize\n",
                "        row_sums = np.array(batch_matrix.power(2).sum(axis=1))\n",
                "        row_norms = np.sqrt(row_sums).flatten()\n",
                "        row_norms[row_norms == 0] = 1.0\n",
                "        inv_norms = 1.0 / row_norms\n",
                "        batch_matrix = diags(inv_norms) @ batch_matrix\n",
                "        \n",
                "        batch_idx = len(saved_batches)\n",
                "        filename = f\"user_profiles_part_{batch_idx}.npz\"\n",
                "        path = os.path.join(parts_dir, filename)\n",
                "        save_npz(path, batch_matrix)\n",
                "        \n",
                "        id_path = path.replace(\".npz\", \"_ids.csv\")\n",
                "        pd.DataFrame(current_batch_ids, columns=['user_id']).to_csv(id_path, index=False)\n",
                "        saved_batches.append(path)\n",
                "        print(f\"Saved final batch {batch_idx}: {batch_matrix.shape} to {filename}\")\n",
                "        \n",
                "    print(f\"\\nUser Profile Construction Complete. Saved {len(saved_batches)} parts.\")\n",
                "    return saved_batches"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "451bc1a4",
            "metadata": {},
            "source": [
                "## 4.2. Handle cold-start users (Popular Item Features Strategy)\n",
                "\n",
                "### Subtask 1: Define what a cold-start user is\n",
                "A **Cold-Start User** is a new user who has not interacted with (rated or viewed) any items in the system yet.\n",
                "Since there is no historical data to compute a personalized profile or find similar users, traditional Collaborative Filtering fails.\n",
                "To address this, we use a **Popularity-Based** or **Demographic-Based** strategy to generate an initial profile.\n",
                "Here, we use the **Popular Item Features** strategy: we assume a new user is likely to be interested in what the majority of people like."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "914b7484",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 2: Identify popular items\n",
                "def identify_popular_items(df_interactions, top_n=50):\n",
                "    \"\"\"\n",
                "    Identifies the top N most rated items.\n",
                "    \"\"\"\n",
                "    print(f\"Identifying top {top_n} popular items...\")\n",
                "    popular_counts = df_interactions['item_id'].value_counts().head(top_n)\n",
                "    popular_item_ids = popular_counts.index.tolist()\n",
                "    print(f\"Found {len(popular_item_ids)} popular items.\")\n",
                "    return popular_item_ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c45e2fbb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 3: Extract feature vectors of popular items\n",
                "def extract_popular_vectors(popular_item_ids, item_feature_matrix, df_items_map):\n",
                "    \"\"\"\n",
                "    Retrieves the sparse feature vectors for the popular items.\n",
                "    \"\"\"\n",
                "    print(\"Extracting feature vectors for popular items...\")\n",
                "    # Map IDs to matrix indices\n",
                "    item_to_idx = {iid: idx for idx, iid in enumerate(df_items_map['item_id'])}\n",
                "    \n",
                "    indices = []\n",
                "    for iid in popular_item_ids:\n",
                "        if iid in item_to_idx:\n",
                "            indices.append(item_to_idx[iid])\n",
                "            \n",
                "    if not indices:\n",
                "        print(\"Warning: No popular items found in feature matrix.\")\n",
                "        return None\n",
                "        \n",
                "    pop_vectors = item_feature_matrix[indices]\n",
                "    print(f\"Extracted shape: {pop_vectors.shape}\")\n",
                "    return pop_vectors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "26f8c591",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 4 & 5: Construct and Normalize cold-start profile\n",
                "def construct_cold_start_profile(df_interactions, item_feature_matrix, df_items_map, top_n=50):\n",
                "    \"\"\"\n",
                "    Creates a single profile vector representing the 'average' user based on popular items.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Constructing Cold-Start User Profile ---\")\n",
                "    \n",
                "    # 1. Identify Popular Items\n",
                "    pop_ids = identify_popular_items(df_interactions, top_n)\n",
                "    \n",
                "    # 2. Extract Vectors\n",
                "    pop_vectors = extract_popular_vectors(pop_ids, item_feature_matrix, df_items_map)\n",
                "    \n",
                "    if pop_vectors is None:\n",
                "        # Return zero vector if fails\n",
                "        return csr_matrix((1, item_feature_matrix.shape[1]))\n",
                "    \n",
                "    # 3. Average (Centroid)\n",
                "    # sum along axis 0 (items), then divide by count\n",
                "    cold_start_vec = pop_vectors.sum(axis=0) / pop_vectors.shape[0]\n",
                "    cold_start_vec = csr_matrix(cold_start_vec)\n",
                "    \n",
                "    # 4. Normalize (Subtask 5)\n",
                "    # L2 Normalization to ensure unit length\n",
                "    norm = np.linalg.norm(cold_start_vec.data)\n",
                "    if norm > 0:\n",
                "        cold_start_vec = cold_start_vec / norm\n",
                "        \n",
                "    print(f\"Cold-start profile constructed. Shape: {cold_start_vec.shape}\")\n",
                "    return cold_start_vec"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba89c9fc",
            "metadata": {},
            "source": [
                "### Subtask 6: Explain when this profile is used\n",
                "This **Cold-Start Profile** is used whenever the system encounters a user with **zero interactions** (or fewer than a threshold, e.g., < 3).\n",
                "Instead of returning random items, we use this profile to calculate cosine similarity against all items, effectively returning items that differ slightly from pure popularity but are semantically similar to the popular 'consensus'.\n",
                "\n",
                "### Subtask 7: Justify the strategy\n",
                "**Justification**:\n",
                "1.  **Robustness**: Popular items are statistically significant 'safe bets' for unknown users.\n",
                "2.  **Content-Aware**: By averaging *features* of popular items rather than just recommending IDs, we can recommend *niche* items that are similar content-wise to popular ones, improving diversity (Serendipity) compared to a simple \"Top-N Popular\" list.\n",
                "3.  **Simplicity**: It effectively boosts the user into the vector space immediately without requiring expensive model retraining (SVD) or demographic data lookup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4a476d12",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main Execution for Cold Start (Function Wrapper)\n",
                "def run_cold_start_module(df_interactions, item_feature_matrix, df_items_map):\n",
                "    \"\"\"\n",
                "    Runs the cold start profile construction and saves the result.\n",
                "    \"\"\"\n",
                "    print(\"\\n=== Running Cold-Start Module ===\")\n",
                "    cold_user_profile = construct_cold_start_profile(df_interactions, item_feature_matrix, df_items_map)\n",
                "    \n",
                "    # Save result\n",
                "    save_path = os.path.join(RESULTS_DIR, \"cold_start_profile.npz\")\n",
                "    save_npz(save_path, cold_user_profile)\n",
                "    print(f\"Saved cold-start profile to {save_path}\")\n",
                "    return cold_user_profile"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bb8f9c95",
            "metadata": {},
            "source": [
                "## 5. Similarity Computation and Recommendation\n",
                "\n",
                "We now calculate the similarity between the user profile and all items to generate recommendations.\n",
                "\n",
                "### Subtask 1: Ensure vector space alignment\n",
                "We verify that the User Vector and Item Feature Matrix share the same number of dimensions before proceeding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "63e46f73",
            "metadata": {},
            "outputs": [],
            "source": [
                "def check_vector_alignment(user_vec, item_matrix):\n",
                "    \"\"\"\n",
                "    Verifies that user vector and item matrix have consistent dimensions.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Verifying Vector Alignment ---\")\n",
                "    user_dim = user_vec.shape[1]\n",
                "    item_dim = item_matrix.shape[1]\n",
                "    \n",
                "    if user_dim != item_dim:\n",
                "        raise ValueError(f\"Dimension mismatch! User: {user_dim}, Item: {item_dim}\")\n",
                "        \n",
                "    print(f\"Alignment Verified. Dimensions: {user_dim}\")\n",
                "    return True"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "329318fb",
            "metadata": {},
            "source": [
                "### Subtask 2: Define cosine similarity formally\n",
                "\n",
                "**Cosine Similarity** measures the cosine of the angle between two non-zero vectors. \n",
                "$$ \\text{similarity} = \\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{||\\mathbf{A}|| \\cdot ||\\mathbf{B}||} $$\n",
                "\n",
                "Since our vectors (both TF-IDF/Item vectors and User vectors) effectively undergo L2 normalization during their construction, their magnitudes are close to 1. Thus, the calculation simplifies to the **Dot Product**:\n",
                "$$ \\text{similarity} \\approx \\mathbf{A} \\cdot \\mathbf{B} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d355208c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 3: Compute userâ€“item similarity scores\n",
                "def compute_cosine_similarity(user_vec, item_matrix):\n",
                "    \"\"\"\n",
                "    Computes Dot Product between User Vector and all Item Vectors.\n",
                "    Assumes vectors are L2 normalized.\n",
                "    \"\"\"\n",
                "    print(\"Computing Cosine Similarity...\")\n",
                "    \n",
                "    # Dot Product: (1 x F) dot (N x F)^T = (1 x N)\n",
                "    # Scipy sparse optimization\n",
                "    similarity_scores = item_matrix.dot(user_vec.T)\n",
                "    \n",
                "    # Convert to dense array for easier handling [N x 1] -> [N]\n",
                "    similarity_scores = similarity_scores.toarray().flatten()\n",
                "    \n",
                "    print(f\"Computed {len(similarity_scores)} similarity scores.\")\n",
                "    return similarity_scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7aab2f06",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 4: Store similarity scores properly\n",
                "def save_similarity_scores(scores, item_ids, filename=\"similarity_scores.csv\"):\n",
                "    \"\"\"\n",
                "    Saves the full list of scores to results for audit.\n",
                "    \"\"\"\n",
                "    print(f\"Saving similarity scores to {filename}...\")\n",
                "    path = os.path.join(RESULTS_DIR, filename)\n",
                "    \n",
                "    # Create DataFrame\n",
                "    df_scores = pd.DataFrame({\n",
                "        'item_id': item_ids,\n",
                "        'score': scores\n",
                "    })\n",
                "    \n",
                "    # Sort desceding\n",
                "    df_scores = df_scores.sort_values(by='score', ascending=False)\n",
                "    \n",
                "    # Save CSV (potentially large, so maybe just top 100k if really huge, but here we save all)\n",
                "    df_scores.to_csv(path, index=False)\n",
                "    print(\"File saved.\")\n",
                "    return df_scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ce12bd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 5: Verify similarity results\n",
                "def verify_similarity_results(scores):\n",
                "    \"\"\"\n",
                "    Checks valid range [-1, 1] for cosine similarity.\n",
                "    \"\"\"\n",
                "    print(\"Verifying similarity scores...\")\n",
                "    min_s = scores.min()\n",
                "    max_s = scores.max()\n",
                "    \n",
                "    print(f\"Range: [{min_s:.4f}, {max_s:.4f}]\")\n",
                "    \n",
                "    if min_s < -1.01 or max_s > 1.01:\n",
                "        print(\"WARNING: Scores out of expected cosine range [-1, 1]. Check normalization.\")\n",
                "    else:\n",
                "        print(\"Verification Passed: Scores within valid range.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "407f431d",
            "metadata": {},
            "source": [
                "### Subtask 6: Explain what similarity scores mean\n",
                "\n",
                "The **Similarity Score** (ranging from -1 to 1) quantifies how close the item's content is to the user's preference profile.\n",
                "- **Approaching 1**: The item is very semantically similar to what the user likes (or the popular consensus in the cold-start case).\n",
                "- **Approaching 0**: The item is orthogonal (unrelated) to the user's profile.\n",
                "- **Approaching -1**: The item is opposite (rare in positive-only Feature spaces like TF-IDF, but possible mathematically)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5cae4eaf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main Execution for Similarity (Function Wrapper)\n",
                "def run_similarity_module(user_vec, item_matrix, df_items_map):\n",
                "    \"\"\"\n",
                "    Runs the similarity pipeline.\n",
                "    \"\"\"\n",
                "    print(\"\\n=== Running Similarity Component ===\")\n",
                "    \n",
                "    # 1. Check Alignment\n",
                "    check_vector_alignment(user_vec, item_matrix)\n",
                "    \n",
                "    # 2. Compute\n",
                "    scores = compute_cosine_similarity(user_vec, item_matrix)\n",
                "    \n",
                "    # 3. Verify\n",
                "    verify_similarity_results(scores)\n",
                "    \n",
                "    # 4. Save\n",
                "    df_scored = save_similarity_scores(scores, df_items_map['item_id'], filename=\"cold_start_similarity_scores.csv\")\n",
                "    \n",
                "    return df_scored"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1b33c87e",
            "metadata": {},
            "source": [
                "## 5.2. Generate Top-N Recommendations\n",
                "\n",
                "We rank items by their similarity scores and exclude items the user has already rated to generate the final Top-N list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6aeadad0",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Subtask 1: Decide which users you will generate recommendations for\n",
                "def get_target_users(df_interactions, cold_start_profile, n_existing=2):\n",
                "    \"\"\"\n",
                "    Selects valid users for demonstration: 1 Cold Start (simulated) + N existing users.\n",
                "    Returns a dictionary of {user_label: user_profile_vector/user_id}\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Selecting Target Users ---\")\n",
                "    target_users = {}\n",
                "    \n",
                "    # 1. Cold Start User\n",
                "    target_users['Cold_Start_User'] = {\n",
                "        'type': 'cold',\n",
                "        'data': cold_start_profile\n",
                "    }\n",
                "    \n",
                "    # 2. Existing Users (Pick random high-activity users)\n",
                "    user_counts = df_interactions['user_id'].value_counts()\n",
                "    active_users = user_counts.head(50).index.tolist()\n",
                "    selected_existing = active_users[:n_existing]\n",
                "    \n",
                "    for uid in selected_existing:\n",
                "        target_users[f'User_{uid}'] = {\n",
                "            'type': 'existing',\n",
                "            'data': uid # We will need to fetch their vector later or re-compute it\n",
                "        }\n",
                "        \n",
                "    print(f\"Selected {len(target_users)} target users: {list(target_users.keys())}\")\n",
                "\n",
                "    return target_users\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a9c7f627",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_target_users_1(df_interactions, cold_start_profile, n_existing=2, user_col='user_id'):\n",
                "    print(\"\\n--- Selecting Target Users ---\")\n",
                "    target_users = {\n",
                "        'Cold_Start_User': {'type': 'cold', 'data': cold_start_profile}\n",
                "    }\n",
                "\n",
                "    # Validate df\n",
                "    if df_interactions is None or len(df_interactions) == 0:\n",
                "        print(\"WARNING: df_interactions is empty. No existing users can be selected.\")\n",
                "        return target_users\n",
                "\n",
                "    if user_col not in df_interactions.columns:\n",
                "        raise ValueError(f\"'{user_col}' not found in df_interactions columns: {list(df_interactions.columns)}\")\n",
                "\n",
                "    user_counts = df_interactions[user_col].dropna().value_counts()\n",
                "    if len(user_counts) == 0:\n",
                "        print(f\"WARNING: No valid users found in column '{user_col}'.\")\n",
                "        return target_users\n",
                "\n",
                "    active_users = user_counts.head(50).index.tolist()\n",
                "    selected_existing = active_users[:n_existing]\n",
                "\n",
                "    for uid in selected_existing:\n",
                "        target_users[f'User_{uid}'] = {'type': 'existing', 'data': uid}\n",
                "\n",
                "    print(f\"Selected {len(target_users)} target users: {list(target_users.keys())}\")\n",
                "    return target_users\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ce0c1dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 2: Build â€œalready-rated itemsâ€ set per user\n",
                "def get_user_rated_items(df_interactions, user_id):\n",
                "    \"\"\"\n",
                "    Returns a set of item_ids that the user has already interacted with.\n",
                "    \"\"\"\n",
                "    if user_id is None: # Cold start\n",
                "        return set()\n",
                "        \n",
                "    user_data = df_interactions[df_interactions['user_id'] == user_id]\n",
                "    rated_items = set(user_data['item_id'].unique())\n",
                "    # print(f\"User {user_id} has rated {len(rated_items)} items.\")\n",
                "    return rated_items"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b86234e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 3 & 4: Filter and Rank candidate items\n",
                "def rank_and_filter_items(similarity_scores, item_ids, rated_items_set):\n",
                "    \"\"\"\n",
                "    - Pairs items with scores.\n",
                "    - Removes already rated items.\n",
                "    - Sorts by score descending.\n",
                "    \"\"\"\n",
                "    print(f\"Ranking items... (Total candidates: {len(item_ids)}) \")\n",
                "    \n",
                "    # Create a list of tuples: (score, item_id)\n",
                "    # We assume similarity_scores and item_ids are aligned by index\n",
                "    candidates = []\n",
                "    \n",
                "    for score, iid in zip(similarity_scores, item_ids):\n",
                "        if iid not in rated_items_set:\n",
                "            candidates.append((score, iid))\n",
                "            \n",
                "    print(f\"Filtered out {len(item_ids) - len(candidates)} rated items. Remaining candidates: {len(candidates)}\")\n",
                "    \n",
                "    # Sort descending by score (Manual sort)\n",
                "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
                "    \n",
                "    return candidates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cd6b0162",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 5: Select Top-10 and Top-20\n",
                "def generate_top_n_recommendations(sorted_candidates, top_n_list=[10, 20]):\n",
                "    \"\"\"\n",
                "    Slices the sorted list to get top N.\n",
                "    \"\"\"\n",
                "    results = {}\n",
                "    for n in top_n_list:\n",
                "        results[n] = sorted_candidates[:n]\n",
                "        \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b49edefc",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 6: Save recommendations in report-friendly format\n",
                "def save_recommendations(user_label, top_n_results, df_items_map):\n",
                "    \"\"\"\n",
                "    Saves top-20 recommendations to CSV with details (Title, Category, Score).\n",
                "    \"\"\"\n",
                "    print(f\"Saving recommendations for {user_label}...\")\n",
                "    \n",
                "    # Map item_id to details\n",
                "    item_map = df_items_map.set_index('item_id').to_dict('index')\n",
                "    \n",
                "    # We focus on the largest N (Top 20) for saving\n",
                "    max_n = max(top_n_results.keys())\n",
                "    top_items = top_n_results[max_n]\n",
                "    \n",
                "    data = []\n",
                "    rank = 1\n",
                "    for score, iid in top_items:\n",
                "        info = item_map.get(iid, {})\n",
                "        row = {\n",
                "            'Rank': rank,\n",
                "            'User': user_label,\n",
                "            'Item_ID': iid,\n",
                "            'Score': round(score, 6),\n",
                "            'Title': info.get('title', 'Unknown'),\n",
                "            'Category': info.get('categories', 'Unknown')\n",
                "        }\n",
                "        data.append(row)\n",
                "        rank += 1\n",
                "        \n",
                "    df_recs = pd.DataFrame(data)\n",
                "    filename = f\"recommendations_{user_label}.csv\"\n",
                "    path = os.path.join(RESULTS_DIR, filename)\n",
                "    df_recs.to_csv(path, index=False)\n",
                "    \n",
                "    print(f\"Saved to {path}\")\n",
                "    return df_recs"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "967d4e7c",
            "metadata": {},
            "source": [
                "### Subtask 8: Explanation of ranking logic\n",
                "\n",
                "The ranking is purely based on the **Cosine Similarity Score**.\n",
                "1.  We calculate the similarity between the User Profile (weighted average of their history) and every Item Vector.\n",
                "2.  We **exclude** items the user has already rated to ensure novelty.\n",
                "3.  We **sort** the remaining items in descending order of similarity.\n",
                "4.  The top items represented the \"best match\" in the vector space."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4db43d3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 7: Provide example outputs for 2-3 users (Orchestrator)\n",
                "def run_recommendation_pipeline(df_interactions, item_feature_matrix, df_items_map, cold_start_profile):\n",
                "    \"\"\"\n",
                "    Runs the full recommendation process for selected users.\n",
                "    \"\"\"\n",
                "    print(\"\\n=== Running Recommendation Pipeline ===\")\n",
                "    \n",
                "    # 1. Select Users\n",
                "    target_users = get_target_users(df_interactions, cold_start_profile, n_existing=2)\n",
                "    \n",
                "    all_recs = []\n",
                "    \n",
                "    for label, info in target_users.items():\n",
                "        print(f\"\\nProcessing {label}...\")\n",
                "        \n",
                "        # Get User Vector\n",
                "        if info['type'] == 'cold':\n",
                "            user_vec = info['data']\n",
                "            rated_items = set()\n",
                "        else:\n",
                "            # Re-construct user vector on the fly for demonstration (or load if we saved all)\n",
                "            # Here we cheat/reuse the build logic for single user or simplest: just accept we saved them?\n",
                "            # Since we saved them in batches, loading one is hard. Let's recompute it fast.\n",
                "            uid = info['data']\n",
                "            rated_items = get_user_rated_items(df_interactions, uid)\n",
                "            \n",
                "            # Helper to get vector (simplified version of build_profiles)\n",
                "            item_to_idx = {iid: idx for idx, iid in enumerate(df_items_map['item_id'])}\n",
                "            indices = [item_to_idx[iid] for iid in rated_items if iid in item_to_idx]\n",
                "            \n",
                "            if not indices:\n",
                "                 user_vec = csr_matrix((1, item_feature_matrix.shape[1]))\n",
                "            else:\n",
                "                # We need ratings too for weighted avg\n",
                "                user_data = df_interactions[df_interactions['user_id'] == uid]\n",
                "                ratings_map = temp_r_map = dict(zip(user_data['item_id'], user_data['rating']))\n",
                "                \n",
                "                # Re-extract to be safe (slow but correct for 1 user)\n",
                "                valid_indices = []\n",
                "                valid_ratings = []\n",
                "                for iid in rated_items:\n",
                "                    if iid in item_to_idx:\n",
                "                        valid_indices.append(item_to_idx[iid])\n",
                "                        valid_ratings.append(ratings_map[iid])\n",
                "                        \n",
                "                item_vecs = item_feature_matrix[valid_indices]\n",
                "                ratings_arr = np.array(valid_ratings).reshape(-1, 1)\n",
                "                weighted = item_vecs.multiply(ratings_arr).sum(axis=0)\n",
                "                weighted /= np.sum(valid_ratings)\n",
                "                user_vec = csr_matrix(weighted)\n",
                "                \n",
                "                # Normalize\n",
                "                norm = np.linalg.norm(user_vec.data)\n",
                "                if norm > 0: user_vec = user_vec / norm\n",
                "        \n",
                "        # 2. Compute Similarity\n",
                "        scores = compute_cosine_similarity(user_vec, item_feature_matrix)\n",
                "        \n",
                "        # 3. Filter & Rank\n",
                "        item_ids = df_items_map['item_id'].tolist()\n",
                "        candidates = rank_and_filter_items(scores, item_ids, rated_items)\n",
                "        \n",
                "        # 4. Top N\n",
                "        top_results = generate_top_n_recommendations(candidates, [10, 20])\n",
                "        \n",
                "        # 5. Save\n",
                "        df_rec = save_recommendations(label, top_results, df_items_map)\n",
                "        all_recs.append(df_rec)\n",
                "        \n",
                "        print(f\"Top 5 for {label}: \")\n",
                "        print(df_rec[['Title', 'Score']].head(5))\n",
                "    \n",
                "    return all_recs"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc88dce6",
            "metadata": {},
            "source": [
                "# 6. k-Nearest Neighbors (k-NN)\n",
                "\n",
                "## 6.1. Implement Item-Based k-NN\n",
                "\n",
                "We implement a memory-efficient Item-based k-NN. Instead of computing the full $N \\times N$ similarity matrix (which can be huge), we compute similarities row-by-row and only store the **Top-K** nearest neighbors for each item.\n",
                "\n",
                "### Subtask 1: Choose the item representation\n",
                "We use the **Feature Matrix** constructed in Section 3 (`final_feature_matrix`) as the item representation. It combines TF-IDF, numerical, and categorical features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d54ddcbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from scipy.sparse import csr_matrix, vstack\n",
                "import heapq\n",
                "\n",
                "# Subtask 2 & 3: Compute item-item similarity and find k most similar (Memory Efficient)\n",
                "def compute_top_k_similar_items(item_feature_matrix, df_items_map, k_list=[10, 20]):\n",
                "    \"\"\"\n",
                "    Computes cosine similarity for each item against all others and keeps top max(k) neighbors.\n",
                "    Returns a dictionary: {item_id: [(score, neighbor_id), ...]}.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Computing Item-Item Similarity (Top-K) ---\")\n",
                "    \n",
                "    max_k = max(k_list)\n",
                "    n_items = item_feature_matrix.shape[0]\n",
                "    item_ids = df_items_map['item_id'].tolist()\n",
                "    \n",
                "    # Output dictionary\n",
                "    item_neighbors = {}\n",
                "    \n",
                "    # We iterate row by row to save memory\n",
                "    # For better performance, we can process in batches (e.g., 100 rows at a time)\n",
                "    batch_size = 100\n",
                "    \n",
                "    print(f\"Processing {n_items} items in batches of {batch_size}...\")\n",
                "    \n",
                "    for start_idx in range(0, n_items, batch_size):\n",
                "        end_idx = min(start_idx + batch_size, n_items)\n",
                "        \n",
                "        # 1. Get Batch of Item Vectors\n",
                "        batch_vecs = item_feature_matrix[start_idx:end_idx]\n",
                "        \n",
                "        # 2. Compute Similarity against ALL items\n",
                "        # Shape: (Batch, F) @ (N, F).T = (Batch, N)\n",
                "        # Using L2 normalized matrix -> Dot product is Cosine Sim\n",
                "        sim_batch = batch_vecs.dot(item_feature_matrix.T)\n",
                "        \n",
                "        # 3. Extract Top-K for each item in batch\n",
                "        # We need to exclude self-similarity (which is 1.0 at index i)\n",
                "        if isinstance(sim_batch, csr_matrix):\n",
                "            sim_batch = sim_batch.toarray()\n",
                "            \n",
                "        for i in range(len(sim_batch)):\n",
                "            current_item_idx = start_idx + i\n",
                "            current_item_id = item_ids[current_item_idx]\n",
                "            \n",
                "            scores = sim_batch[i]\n",
                "            \n",
                "            # Eliminate self (set to -1)\n",
                "            scores[current_item_idx] = -1.0\n",
                "            \n",
                "            # Find Top K using argpartition (faster than full sort)\n",
                "            # We want top max_k. argpartition puts smallest at front, largest at back.\n",
                "            # So we partition by N - max_k - 1?? No, just use simple sort for clarity if N is small (<10k)\n",
                "            # Or use heapq.nlargest\n",
                "            \n",
                "            # Efficient Top-K indices\n",
                "            # Note: If N ~ 50k, sorting 50k floats 50k times is slow but acceptable for assignment.\n",
                "            top_indices = np.argsort(scores)[-max_k:][::-1]\n",
                "            \n",
                "            neighbors = []\n",
                "            for idx in top_indices:\n",
                "                score = scores[idx]\n",
                "                if score > 0: # Only positive similarity\n",
                "                    neighbor_id = item_ids[idx]\n",
                "                    neighbors.append((float(score), neighbor_id))\n",
                "            \n",
                "            item_neighbors[current_item_id] = neighbors\n",
                "        \n",
                "        if (start_idx // batch_size) % 10 == 0:\n",
                "             print(f\"Processed {end_idx}/{n_items} items...\")\n",
                "             \n",
                "    print(\"Top-K Neighbor computation complete.\")\n",
                "    return item_neighbors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ce41c95",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 4: Define prediction formula (Weighted Average)\n",
                "def predict_rating_knn(user_id, target_item_id, item_neighbors, user_ratings_map, k=20):\n",
                "    \"\"\"\n",
                "    Predicts rating for user u on item i using Item-KNN.\n",
                "    Formula: Sum(sim(i,j) * r_uj) / Sum(|sim(i,j)|)\n",
                "    where j are neighbors of i that u has rated.\n",
                "    \"\"\"\n",
                "    # 1. Get Neighbors of target_item_id\n",
                "    neighbors = item_neighbors.get(target_item_id, [])\n",
                "    \n",
                "    # 2. Filter neighbors to Top-K that User has rated\n",
                "    # Note: item_neighbors is already sorted Top-MaxK. We assume neighbors[:k] restricts to k.\n",
                "    # But usually KNN means \"K nearest neighbors that have a rating\".\n",
                "    # Standard Item-KNN: Find K most similar items (S_k(i)). intersection with I_u.\n",
                "    # OR Find all items in I_u, sort by similarity to i, take top K.\n",
                "    # The latter is better for coverage. \n",
                "    # With pre-computed Top-K item-item, we are limited to the global Top-K similar items.\n",
                "    # If the user hasn't rated any of the global Top-K similar items, we cannot predict.\n",
                "    # We will use the pre-computed neighbors approach (Model-Based KNN).\n",
                "    \n",
                "    top_k_neighbors = neighbors[:k]\n",
                "    \n",
                "    weighted_sum = 0.0\n",
                "    sum_sim = 0.0\n",
                "    \n",
                "    count_contributors = 0\n",
                "    \n",
                "    for score, neighbor_id in top_k_neighbors:\n",
                "        if neighbor_id in user_ratings_map:\n",
                "            r_uj = user_ratings_map[neighbor_id]\n",
                "            weighted_sum += score * r_uj\n",
                "            sum_sim += abs(score)\n",
                "            count_contributors += 1\n",
                "            \n",
                "    # Subtask 5: Handle edge cases\n",
                "    if count_contributors == 0 or sum_sim == 0:\n",
                "        # Fallback: User's average rating or global average\n",
                "        # Returning None to signal \"No Prediction possible via KNN\"\n",
                "        return None \n",
                "        \n",
                "    prediction = weighted_sum / sum_sim\n",
                "    return prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "89cd10a1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 6 & 7: Generate predictions and save\n",
                "def generate_knn_recommendations(target_users, item_neighbors, df_interactions, df_items_map, k_list=[10, 20]):\n",
                "    \"\"\"\n",
                "    Generates Top-N recommendations using KNN for specific users.\n",
                "    Since KNN is a rating predictor, we predict ratings for ALL unrated items and rank them.\n",
                "    This is expensive. For demo, we might only score a candidate set (e.g., top 100 popular unrated).\n",
                "    \"\"\"\n",
                "    print(\"\\n--- Generating KNN Recommendations ---\")\n",
                "    all_results = []\n",
                "    \n",
                "    # Valid items list\n",
                "    all_item_ids = df_items_map['item_id'].tolist()\n",
                "    item_map = df_items_map.set_index('item_id').to_dict('index')\n",
                "    \n",
                "    for user_label, info in target_users.items():\n",
                "        if info['type'] == 'cold':\n",
                "            print(f\"Skipping {user_label} for KNN (Requires history).\")\n",
                "            continue\n",
                "            \n",
                "        user_id = info['data']\n",
                "        print(f\"generating for {user_label} ({user_id})...\")\n",
                "        \n",
                "        # 1. Build User Rating Map\n",
                "        user_data = df_interactions[df_interactions['user_id'] == user_id]\n",
                "        user_ratings_map = dict(zip(user_data['item_id'], user_data['rating']))\n",
                "        rated_items = set(user_ratings_map.keys())\n",
                "        \n",
                "        # 2. Define Candidates (All items - Rated items)\n",
                "        # heuristic: score only items that appear in neighbors of rated items? (Item-Based expansion)\n",
                "        # This is much faster than scoring ALL items.\n",
                "        candidate_set = set()\n",
                "        for rated_item in rated_items:\n",
                "            # Get neighbors of what user liked\n",
                "            # We look at the precomputed similarity. \n",
                "            # If i is similar to j (rated), then i is a candidate.\n",
                "            # But our map is i -> neighbors. It's symmetric. \n",
                "            neighbors = item_neighbors.get(rated_item, [])\n",
                "            for s, n_id in neighbors:\n",
                "                if n_id not in rated_items:\n",
                "                    candidate_set.add(n_id)\n",
                "        \n",
                "        print(f\"Identified {len(candidate_set)} candidate items via neighbor expansion.\")\n",
                "        \n",
                "        # 3. Predict & Rank\n",
                "        predictions = []\n",
                "        for k in k_list:\n",
                "            # We generate for largest K, then slice\n",
                "            pass\n",
                "            \n",
                "        # Use max K for finding best items\n",
                "        max_k = max(k_list)\n",
                "        \n",
                "        candidates_scored = []\n",
                "        for item_id in candidate_set:\n",
                "            pred = predict_rating_knn(user_id, item_id, item_neighbors, user_ratings_map, k=max_k)\n",
                "            if pred is not None:\n",
                "                candidates_scored.append((pred, item_id))\n",
                "                \n",
                "        # Sort\n",
                "        candidates_scored.sort(key=lambda x: x[0], reverse=True)\n",
                "        \n",
                "        # Select Top 20\n",
                "        top_20 = candidates_scored[:20]\n",
                "        \n",
                "        # Save CSV\n",
                "        out_data = []\n",
                "        rank = 1\n",
                "        for score, iid in top_20:\n",
                "            meta = item_map.get(iid, {})\n",
                "            out_data.append({\n",
                "                'Rank': rank,\n",
                "                'User': user_id,\n",
                "                'Item_ID': iid,\n",
                "                'Predicted_Rating': round(score, 4),\n",
                "                'Title': meta.get('title', 'Unknown'),\n",
                "                'Method': f'Item-KNN (k={max_k})'\n",
                "            })\n",
                "            rank += 1\n",
                "            \n",
                "        df_out = pd.DataFrame(out_data)\n",
                "        filename = f\"knn_recommendations_{user_id}.csv\"\n",
                "        path = os.path.join(RESULTS_DIR, filename)\n",
                "        df_out.to_csv(path, index=False)\n",
                "        print(f\"Saved KNN recs to {path}\")\n",
                "        all_results.append(df_out)\n",
                "        \n",
                "    return all_results"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "441d9c30",
            "metadata": {},
            "source": [
                "## 6.2. Compare Content-Based and k-NN Approaches\n",
                "\n",
                "We compare the two methods using a consistent evaluation setup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "11d1beb9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 1-5: Comparison Module\n",
                "def evaluate_and_compare(target_users, df_interactions, item_feature_matrix, item_neighbors, df_items_map):\n",
                "    \"\"\"\n",
                "    Evaluates CB and KNN on a 'Leave-One-Out' task for the existing users.\n",
                "    Metric: Hit Rate @ 10 (Is the hidden item in Top 10?)\n",
                "    Interpretation: Which method retrieves the actual hidden interaction better?\n",
                "    \"\"\"\n",
                "    print(\"\\n=== Comparing Content-Based vs k-NN (Leave-One-Out Evaluation) ===\")\n",
                "    \n",
                "    results = []\n",
                "    \n",
                "    for label, info in target_users.items():\n",
                "        if info['type'] != 'existing':\n",
                "            continue\n",
                "            \n",
                "        user_id = info['data']\n",
                "        \n",
                "        # 1. Get User History\n",
                "        user_data = df_interactions[df_interactions['user_id'] == user_id]\n",
                "        if len(user_data) < 2:\n",
                "            continue\n",
                "            \n",
                "        # 2. Leave One Out (Last one)\n",
                "        hidden_item = user_data.iloc[-1]['item_id']\n",
                "        train_items = set(user_data.iloc[:-1]['item_id'].unique())\n",
                "        train_map = dict(zip(user_data.iloc[:-1]['item_id'], user_data.iloc[:-1]['rating']))\n",
                "        \n",
                "        print(f\"Evaluating User {user_id}. Hidden Item: {hidden_item}\")\n",
                "        \n",
                "        # --- Method A: Content-Based ---\n",
                "        # Rebuild profile from TRAIN items only\n",
                "        # (Simplified profile build for single user)\n",
                "        item_to_idx = {iid: idx for idx, iid in enumerate(df_items_map['item_id'])}\n",
                "        indices = [item_to_idx[iid] for iid in train_items if iid in item_to_idx]\n",
                "        \n",
                "        cb_hit = 0\n",
                "        knn_hit = 0\n",
                "        \n",
                "        if indices:\n",
                "            item_vecs = item_feature_matrix[indices]\n",
                "            ratings_arr = np.array([train_map[iid] for iid in train_items if iid in item_to_idx]).reshape(-1, 1)\n",
                "            # Weighted Avg\n",
                "            user_vec = item_vecs.multiply(ratings_arr).sum(axis=0)\n",
                "            user_vec = csr_matrix(user_vec / np.sum(ratings_arr))\n",
                "            # Normalize\n",
                "            if np.linalg.norm(user_vec.data) > 0:\n",
                "                user_vec = user_vec / np.linalg.norm(user_vec.data)\n",
                "                \n",
                "            # Predict (Score all items)\n",
                "            scores = compute_cosine_similarity(user_vec, item_feature_matrix)\n",
                "            \n",
                "            # Rank (Exclude Train)\n",
                "            # We include Hidden Item in candidates\n",
                "            cb_candidates = []\n",
                "            all_ids = df_items_map['item_id'].tolist()\n",
                "            for s, iid in zip(scores, all_ids):\n",
                "                if iid not in train_items:\n",
                "                    cb_candidates.append((s, iid))\n",
                "            cb_candidates.sort(key=lambda x: x[0], reverse=True)\n",
                "            \n",
                "            # Check Hit @ 10\n",
                "            top_10 = [c[1] for c in cb_candidates[:10]]\n",
                "            if hidden_item in top_10:\n",
                "                cb_hit = 1\n",
                "        \n",
                "        # --- Method B: Item-KNN ---\n",
                "        # Predict Score for Hidden Item vs Random 100 negatives? \n",
                "        # Or just rank all candidates like CB? \n",
                "        # KNN ranks by predicted rating.\n",
                "        # We use strict Candidate set = [Hidden Item] + [100 Random Unrated]\n",
                "        # To save time vs scoring 50k items.\n",
                "        negatives = []\n",
                "        import random\n",
                "        while len(negatives) < 100:\n",
                "            i_rand = random.choice(all_ids)\n",
                "            if i_rand not in train_items and i_rand != hidden_item:\n",
                "                negatives.append(i_rand)\n",
                "                \n",
                "        test_candidates = [hidden_item] + negatives\n",
                "        \n",
                "        knn_scores = []\n",
                "        for cand in test_candidates:\n",
                "            score = predict_rating_knn(user_id, cand, item_neighbors, train_map, k=20)\n",
                "            if score is None: score = 0 # Default low\n",
                "            knn_scores.append((score, cand))\n",
                "            \n",
                "        knn_scores.sort(key=lambda x: x[0], reverse=True)\n",
                "        top_10_knn = [c[1] for c in knn_scores[:10]]\n",
                "        \n",
                "        if hidden_item in top_10_knn:\n",
                "            knn_hit = 1\n",
                "            \n",
                "        results.append({\n",
                "            'User': user_id,\n",
                "            'CB_Hit_10': cb_hit,\n",
                "            'KNN_Hit_10': knn_hit,\n",
                "            'Hidden_Item': hidden_item\n",
                "        })\n",
                "        \n",
                "    # Subtask 4: Build Comparison Table\n",
                "    df_res = pd.DataFrame(results)\n",
                "    print(\"\\n--- Evaluation Results (Hit Rate @ 10) ---\")\n",
                "    print(df_res)\n",
                "    save_path = os.path.join(RESULTS_DIR, \"method_comparison.csv\")\n",
                "    df_res.to_csv(save_path, index=False)\n",
                "\n",
                "    \n",
                "    # Subtask 5: Interpret\n",
                "    cb_acc = df_res['CB_Hit_10'].mean()\n",
                "    knn_acc = df_res['KNN_Hit_10'].mean()\n",
                "    \n",
                "    print(\"\\n--- Interpretation ---\")\n",
                "    print(f\"Content-Based Hit Rate: {cb_acc:.2f}\")\n",
                "    print(f\"Item-KNN Hit Rate: {knn_acc:.2f}\")\n",
                "    \n",
                "    if knn_acc > cb_acc:\n",
                "        print(\"Conclusion: k-NN performed better. Collaborative signals (ratings) might be stronger than content Metadata here.\")\n",
                "    elif cb_acc > knn_acc:\n",
                "        print(\"Conclusion: Content-Based performed better. Metadata specificities might be more effective than sparse rating overlaps.\")\n",
                "    else:\n",
                "        print(\"Conclusion: Both methods performed similarly.\")\n",
                "        \n",
                "    return df_res"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5484a1b7",
            "metadata": {},
            "source": [
                "# 7. Complete Numerical Example\n",
                "\n",
                "## 7.1. Step-by-Step Numerical Walkthrough\n",
                "This section provides a detailed numerical example using a small subset (3-5 items) to transparently demonstrate the calculations behind the scenes.\n",
                "\n",
                "### Subtask 1: Select 3â€“5 sample items"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "55dee9b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def select_sample_items(df_items, n=5):\n",
                "    \"\"\"\n",
                "    Selects the first n items for distinct demonstration.\n",
                "    \"\"\"\n",
                "    print(f\"\\n--- [Numerical Example] Selecting {n} Sample Items ---\")\n",
                "    \n",
                "    # We pick the head. If text source not there, we ensure it is.\n",
                "    # We assume 'text_source' column exists or we recreate it briefly.\n",
                "    sample = df_items.head(n).copy()\n",
                "    if 'text_source' not in sample.columns:\n",
                "        # Simple fallback re-creation just for this df\n",
                "        sample['text_source'] = sample['title'].fillna('') + \" \" + sample['categories'].fillna('')\n",
                "        \n",
                "    # Display\n",
                "    for i, row in sample.iterrows():\n",
                "        print(f\"Item {row['item_id']}: {row['title']} | Text: {row['text_source'][:50]}...\")\n",
                "        \n",
                "    return sample"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73f2e1da",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 2-4: Build Vocabulary and Compute TF/IDF (Small Scale)\n",
                "def run_step_by_step_tfidf(sample_df):\n",
                "    \"\"\"\n",
                "    Manually computes TF, IDF, and TF-IDF for the sample set to show the math.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- [Numerical Example] TF-IDF Calculation ---\")\n",
                "    \n",
                "    # 1. Tokenize\n",
                "    texts = sample_df['text_source'].tolist()\n",
                "    processed_docs = manual_tokenize_and_clean(texts)\n",
                "    \n",
                "    # 2. Build Vocabulary (Subtask 2)\n",
                "    # We iterate and find unique terms just for this subset\n",
                "    unique_terms = sorted(set(term for doc in processed_docs for term in doc))\n",
                "    vocab = {term: i for i, term in enumerate(unique_terms)}\n",
                "    print(f\"\\nSample Vocabulary ({len(vocab)} terms): {list(vocab.keys())}\")\n",
                "    \n",
                "    # 3. Compute TF (Subtask 3)\n",
                "    # TF(t, d) = count of t in d\n",
                "    tfs = []\n",
                "    print(\"\\nTerm Frequencies (TF):\")\n",
                "    for i, doc in enumerate(processed_docs):\n",
                "        counts = Counter(doc)\n",
                "        row = [counts[term] for term in unique_terms]\n",
                "        tfs.append(row)\n",
                "        print(f\"Doc {i} ({sample_df.iloc[i]['item_id']}): {dict(zip(unique_terms, row))}\")\n",
                "    \n",
                "    # 4. Compute IDF (Subtask 4)\n",
                "    # IDF(t) = log((N+1) / (df(t)+1)) + 1\n",
                "    N = len(processed_docs)\n",
                "    dfs = [sum(1 for doc in processed_docs for term in unique_terms if term in doc) for term in unique_terms]\n",
                "    # Wait, the list comprehension above is slightly wrong 'if term in doc' check\n",
                "    # Correct Logic: for each term, count docs containing it.\n",
                "    dfs = []\n",
                "    for term in unique_terms:\n",
                "        count = sum(1 for doc in processed_docs if term in doc)\n",
                "        dfs.append(count)\n",
                "    \n",
                "    idfs = []\n",
                "    print(f\"\\nInverse Document Frequencies (IDF) [log((N+1)/(df+1)) + 1]:\")\n",
                "    for term, df in zip(unique_terms, dfs):\n",
                "        val = math.log((N + 1) / (df + 1)) + 1\n",
                "        idfs.append(val)\n",
                "        print(f\"Term '{term}': DF={df}, IDF={val:.4f}\")\n",
                "        \n",
                "    # 5. Compute TF-IDF (Subtask 5)\n",
                "    print(\"\\nTF-IDF Matrix (TF * IDF) before Normalization:\")\n",
                "    tfidf_matrix = []\n",
                "    for i, tf_row in enumerate(tfs):\n",
                "        vec = [tf * idf for tf, idf in zip(tf_row, idfs)]\n",
                "        tfidf_matrix.append(vec)\n",
                "        # Print simplified\n",
                "        vec_str = \", \".join([f\"{v:.2f}\" for v in vec])\n",
                "        print(f\"Doc {i}: [{vec_str}]\")\n",
                "        \n",
                "    # Normalize\n",
                "    print(\"\\nL2 Normalization:\")\n",
                "    final_matrix = []\n",
                "    for i, vec in enumerate(tfidf_matrix):\n",
                "        norm = math.sqrt(sum(v*v for v in vec))\n",
                "        if norm > 0:\n",
                "            norm_vec = [v/norm for v in vec]\n",
                "        else:\n",
                "            norm_vec = vec\n",
                "        final_matrix.append(norm_vec)\n",
                "        norm_vec_str = \", \".join([f\"{v:.3f}\" for v in norm_vec])\n",
                "        print(f\"Doc {i} Normalized: [{norm_vec_str}]\")\n",
                "        \n",
                "    # Return as DataFrame for easier handling downstream\n",
                "    df_tfidf = pd.DataFrame(final_matrix, columns=unique_terms, index=sample_df['item_id'])\n",
                "    \n",
                "    # Save for report\n",
                "    df_tfidf.to_csv(os.path.join(RESULTS_DIR, \"numerical_example_tfidf.csv\"))\n",
                "    return df_tfidf\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f9ab0a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 6: Define Sample User & Ratings\n",
                "def define_sample_user(sample_df):\n",
                "    \"\"\"\n",
                "    Creates a user who rated specific items from the sample.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- [Numerical Example] Defining Sample User ---\")\n",
                "    # Let's say user rated 2 of the 5 items.\n",
                "    # We pick item 0 and item 2\n",
                "    items = sample_df['item_id'].tolist()\n",
                "    if len(items) < 2:\n",
                "         print(\"Not enough items to define sample user.\")\n",
                "         return {}\n",
                "         \n",
                "    # User Ratings\n",
                "    user_ratings = {\n",
                "        items[0]: 5.0, # Loved Item 0\n",
                "        items[1]: 2.0  # Disliked Item 1 (if available)\n",
                "    }\n",
                "    if len(items) > 2:\n",
                "         user_ratings[items[2]] = 4.0\n",
                "    \n",
                "    print(f\"User Ratings: {user_ratings}\")\n",
                "    return user_ratings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0522095c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 7: Construct User Profile\n",
                "def construct_sample_profile(user_ratings, df_tfidf_sample):\n",
                "    \"\"\"\n",
                "    Weighted average of rated item vectors.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- [Numerical Example] User Profile Construction ---\")\n",
                "    \n",
                "    n_features = df_tfidf_sample.shape[1]\n",
                "    terms = df_tfidf_sample.columns.tolist()\n",
                "    \n",
                "    # Initialize sum vector\n",
                "    weighted_sum = np.zeros(n_features)\n",
                "    total_rating = 0.0\n",
                "    \n",
                "    print(\"Calculation (Sum[r * v] / Sum[r]):\")\n",
                "    \n",
                "    for iid, rating in user_ratings.items():\n",
                "        if iid in df_tfidf_sample.index:\n",
                "            vec = df_tfidf_sample.loc[iid].values\n",
                "            weighted_sum += rating * vec\n",
                "            total_rating += rating\n",
                "            print(f\" + (Rating {rating}) * Vector[{iid}]\")\n",
                "            \n",
                "    if total_rating > 0:\n",
                "        user_profile = weighted_sum / total_rating\n",
                "    else:\n",
                "        user_profile = weighted_sum\n",
                "        \n",
                "    # Normalize\n",
                "    norm = np.linalg.norm(user_profile)\n",
                "    if norm > 0:\n",
                "        user_profile = user_profile / norm\n",
                "        \n",
                "    print(f\"\\nFinal Normalized User Profile Vector (Top 5 features):\")\n",
                "    # Display top 5 dim for readability\n",
                "    top_indices = np.argsort(user_profile)[::-1][:5]\n",
                "    for idx in top_indices:\n",
                "        print(f\"'{terms[idx]}': {user_profile[idx]:.4f}\")\n",
                "        \n",
                "    return user_profile"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c154a900",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subtask 8 & 9: Compute Similarity & Rank\n",
                "def compute_sample_similarity_and_rank(user_profile, df_tfidf_sample):\n",
                "    \"\"\"\n",
                "    Dot product execution.\n",
                "    \"\"\"\n",
                "    print(\"\\n--- [Numerical Example] Similarity & Ranking ---\")\n",
                "    \n",
                "    results = []\n",
                "    \n",
                "    for iid, row in df_tfidf_sample.iterrows():\n",
                "        item_vec = row.values\n",
                "        # Dot product\n",
                "        score = np.dot(user_profile, item_vec)\n",
                "        results.append((score, iid))\n",
                "        print(f\"Item {iid}: Score = Dot(User, Item) = {score:.6f}\")\n",
                "        \n",
                "    # Rank\n",
                "    results.sort(key=lambda x: x[0], reverse=True)\n",
                "    \n",
                "    print(\"\\n--- Top Recommendations --- \")\n",
                "    rank = 1\n",
                "    out_list = []\n",
                "    for score, iid in results:\n",
                "        print(f\"{rank}. Item {iid} (Score: {score:.4f})\")\n",
                "        out_list.append({'Rank': rank, 'Item_ID': iid, 'Score': score})\n",
                "        rank += 1\n",
                "        \n",
                "    # Save\n",
                "    pd.DataFrame(out_list).to_csv(os.path.join(RESULTS_DIR, \"numerical_example_results.csv\"), index=False)\n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12da0539",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Orchestrator for Section 7\n",
                "def run_numerical_example_pipeline(df_items):\n",
                "    print(\"\\n==============================================\")\n",
                "    print(\"       STARTING SECTION 7: NUMERICAL EXAMPLE       \")\n",
                "    print(\"==============================================\")\n",
                "    \n",
                "    # 1. Select\n",
                "    sample = select_sample_items(df_items, n=5)\n",
                "    \n",
                "    # 2-5. TF-IDF\n",
                "    df_tfidf_sample = run_step_by_step_tfidf(sample)\n",
                "    \n",
                "    # 6. User\n",
                "    user_ratings = define_sample_user(sample)\n",
                "    \n",
                "    # 7. Profile\n",
                "    user_profile = construct_sample_profile(user_ratings, df_tfidf_sample)\n",
                "    \n",
                "    # 8-9. Similarity & Rank\n",
                "    compute_sample_similarity_and_rank(user_profile, df_tfidf_sample)\n",
                "    \n",
                "    print(\"\\n[Numerical Example Completed Successfully]\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

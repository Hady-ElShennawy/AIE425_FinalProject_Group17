{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5657ee74",
   "metadata": {},
   "source": [
    "# Group 17: \n",
    "### Eyad Medhat 221100279 / Hady Aly 221101190 / Mohamed Mahfouz 221101743 / Omar Mady 221100745"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c9972",
   "metadata": {},
   "source": [
    "# PCA with Maximum Likelihood Estimation (MLE) Approach\n",
    "\n",
    "This notebook implements PCA-based collaborative filtering using the MLE covariance estimation method to handle sparse rating matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794028f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder exists at: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\n",
      "Subfolder exists: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\\plots\n",
      "Subfolder exists: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\\tables\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbe76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder exists at: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\n",
      "Subfolder exists: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\\plots\n",
      "Subfolder exists: d:\\University\\semester 9\\IRS\\AIE425_FinalProject_Group17\\SECTION1_DimensionalityReduction\\results\\tables\n"
     ]
    }
   ],
   "source": [
    "results_dir = ensure_results_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eda2ab",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load the dataset and create the user-item matrix. Identify target items and users for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b26e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found cached sample at: ..\\data\\ml-20m\\ratings_cleaned_sampled.csv\n",
      "Loaded dataset with shape: (1000000, 3)\n",
      "User-Item Matrix dimensions: (96345, 1000)\n",
      " Found requested table at: ..\\results\\tables\\lowest_two_rateditems.csv\n",
      "Loaded target items from file: [1556, 1499]\n",
      "Active targets in matrix: [1556, 1499]\n",
      "Users with missing target ratings: 96329\n"
     ]
    }
   ],
   "source": [
    "ratings_df =load_data()\n",
    "\n",
    "# Fallback to local file if utility function fails\n",
    "if ratings_df is None:\n",
    "    local_file = 'ratings_cleaned_sampled.csv'\n",
    "    if os.path.exists(local_file):\n",
    "        ratings_df = pd.read_csv(local_file)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Dataset not found! Check file paths.\")\n",
    "\n",
    "print(f\"Loaded dataset with shape: {ratings_df.shape}\")\n",
    "\n",
    "# Create user-item matrix\n",
    "ui_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating')\n",
    "print(f\"User-Item Matrix dimensions: {ui_matrix.shape}\")\n",
    "\n",
    "# Load or set target items for prediction\n",
    "targets_df = load_data(table_name='lowest_two_rateditems.csv')\n",
    "\n",
    "target_items = targets_df['movieId'].tolist()[:2]\n",
    "print(f\"Loaded target items from file: {target_items}\")\n",
    "\n",
    "\n",
    "# Filter to active targets in the matrix\n",
    "active_targets = [item for item in target_items if item in ui_matrix.columns]\n",
    "print(f\"Active targets in matrix: {active_targets}\")\n",
    "\n",
    "# Identify users who haven't rated at least one target item\n",
    "users_with_missing = ui_matrix[ui_matrix[active_targets].isna().any(axis=1)].index.tolist()\n",
    "print(f\"Users with missing target ratings: {len(users_with_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4f808",
   "metadata": {},
   "source": [
    "## Step 1: MLE-based Covariance Matrix Construction\n",
    "\n",
    "Calculate the true MLE covariance between items by computing pairwise covariances using only users who rated both items in each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999f170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building MLE Covariance Matrix...\n",
      "Step 1: TRUE MLE Covariance Matrix Generated.\n",
      "    Saved CSV: tables/pca_mle_cov_matrix.csv\n",
      "Step 1 Output Saved: pca_mle_cov_matrix.csv\n",
      "movieId     1         2         3         5         6         7         10     \\\n",
      "movieId                                                                         \n",
      "1        0.784061  0.257519  0.265043  0.193229  0.077289  0.010011  0.095170   \n",
      "2        0.257519  0.965164  0.367336  0.259827  0.262220  0.475421  0.207785   \n",
      "3        0.265043  0.367336  0.936565  0.289819  0.400179  0.192354  0.137546   \n",
      "5        0.193229  0.259827  0.289819  1.044418  0.407888  0.375331  0.513870   \n",
      "6        0.077289  0.262220  0.400179  0.407888  0.795272  0.180567  0.128871   \n",
      "\n",
      "movieId     11        14        16     ...     70286     71535     72998  \\\n",
      "movieId                                ...                                 \n",
      "1        0.245748 -0.044494 -0.069877  ...  0.192374 -0.057573  0.058382   \n",
      "2        0.248989  0.294459 -0.038413  ...  0.592687  0.601078  0.446689   \n",
      "3        0.153344  0.077715  0.236532  ... -0.100175  0.806394 -0.221649   \n",
      "5        0.315761 -0.274892 -0.083983  ...  0.073312  1.189177  1.013938   \n",
      "6        0.058809  0.126885  0.258487  ...  0.394329 -0.047918  0.126699   \n",
      "\n",
      "movieId     73017     74458     78499     79132     80463     81591     81845  \n",
      "movieId                                                                        \n",
      "1        0.008690  0.052876  0.524542  0.077721 -0.053326  0.108010  0.201380  \n",
      "2        0.180021  0.332759  0.412483  0.147776 -0.173073  0.374597  0.296588  \n",
      "3       -0.594051  0.575916  0.197246  0.161114 -0.950328  0.068534  0.319131  \n",
      "5       -0.042705 -0.099685  0.337328  0.412077 -0.036341 -0.068717  0.326389  \n",
      "6        0.361141  0.111194  0.293095  0.153454  0.129159  0.167652  0.808764  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "# Center the data by subtracting item means\n",
    "item_avg = ui_matrix.mean(axis=0)\n",
    "ui_centered = ui_matrix - item_avg\n",
    "\n",
    "# Extract values and dimensions\n",
    "matrix_vals = ui_centered.values\n",
    "n_items = ui_centered.shape[1]\n",
    "item_indices = ui_centered.columns\n",
    "\n",
    "# Initialize covariance matrix\n",
    "cov_matrix = np.zeros((n_items, n_items), dtype=float)\n",
    "\n",
    "print(\"Building MLE Covariance Matrix...\")\n",
    "# Compute pairwise covariances\n",
    "for i in range(n_items):\n",
    "    col_i = matrix_vals[:, i]\n",
    "    for j in range(i, n_items):\n",
    "        col_j = matrix_vals[:, j]\n",
    "        \n",
    "        # Find users who rated both items\n",
    "        valid_mask = ~np.isnan(col_i) & ~np.isnan(col_j)\n",
    "        count = int(valid_mask.sum())\n",
    "\n",
    "        # Calculate MLE covariance\n",
    "        if count == 0:\n",
    "            cov_val = 0.0\n",
    "        else:\n",
    "            cov_val = float(np.dot(col_i[valid_mask], col_j[valid_mask]) / count)\n",
    "\n",
    "        # Store symmetric values\n",
    "        cov_matrix[i, j] = cov_val\n",
    "        cov_matrix[j, i] = cov_val\n",
    "\n",
    "# Convert to DataFrame\n",
    "cov_df = pd.DataFrame(cov_matrix, index=item_indices, columns=item_indices)\n",
    "\n",
    "print(\"Step 1: TRUE MLE Covariance Matrix Generated.\")\n",
    "save_csv(cov_df, \"pca_mle_cov_matrix.csv\")\n",
    "print(\"Step 1 Output Saved: pca_mle_cov_matrix.csv\")\n",
    "print(cov_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da75cf",
   "metadata": {},
   "source": [
    "## Step 2: Latent Space Construction and Peer Discovery\n",
    "\n",
    "Apply eigen-decomposition to extract principal components and identify similar items in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74788b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Eigen-decomposition...\n",
      "\n",
      "Number of components to explain 75% variance: 22\n",
      "Correlation Variance at k=22: 0.7541\n",
      "Selected Top 22 Eigenvalues based on 75% Variance:\n",
      "[143.69768713  44.48094567  34.93584832  28.03784742  27.24015097\n",
      "  26.09275962  24.73083927  23.83401048  23.55443214  23.05144599\n",
      "  22.92263611  22.28116497  22.05522298  21.50783826  21.31747887\n",
      "  21.11426852  21.07358691  20.56912542  20.32480027  20.07447692\n",
      "  20.06109814  19.9205765 ]\n",
      "    Saved CSV: tables/pca_mle_peers.csv\n",
      "Step 2 Output Saved: pca_mle_peers.csv\n",
      "Target 1556 Top-5 Peers: [628, 2167, 1722, 1917, 1801]\n",
      "Target 1499 Top-5 Peers: [2804, 1296, 420, 3623, 4855]\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing Eigen-decomposition...\")\n",
    "\n",
    "# Eigenvalue decomposition\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_df.values)\n",
    "\n",
    "# Sort by eigenvalues (descending)\n",
    "sort_idx = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues = eigenvalues[sort_idx]\n",
    "eigenvectors = eigenvectors[:, sort_idx]\n",
    "\n",
    "# Calculate variance explained\n",
    "total_var = np.sum(eigenvalues)\n",
    "var_ratio = eigenvalues / total_var\n",
    "cumulative_var = np.cumsum(var_ratio)\n",
    "\n",
    "# Determine components for 75% variance\n",
    "k_components = np.argmax(cumulative_var >= 0.75) + 1\n",
    "print(f\"\\nNumber of components to explain 75% variance: {k_components}\")\n",
    "print(f\"Correlation Variance at k={k_components}: {cumulative_var[k_components-1]:.4f}\")\n",
    "\n",
    "print(f\"Selected Top {k_components} Eigenvalues based on 75% Variance:\")\n",
    "print(eigenvalues[:k_components])\n",
    "\n",
    "# Helper function to find similar items in latent space\n",
    "\n",
    "\n",
    "# Get all item IDs\n",
    "all_items = list(cov_df.columns)\n",
    "\n",
    "# Find Top-5 and Top-10 neighbors\n",
    "neighbors_5 = compute_latent_neighbors(\n",
    "    n_comp=k_components, n_neighbors=5,\n",
    "    all_items=all_items, target_list=active_targets, evec_matrix=eigenvectors\n",
    ")\n",
    "\n",
    "neighbors_10 = compute_latent_neighbors(\n",
    "    n_comp=k_components, n_neighbors=10,\n",
    "    all_items=all_items, target_list=active_targets, evec_matrix=eigenvectors\n",
    ")\n",
    "\n",
    "# Create summary table\n",
    "peer_summary = []\n",
    "for target in active_targets:\n",
    "    if target in neighbors_5 and target in neighbors_10:\n",
    "        peer_summary.append({\n",
    "            \"TargetItem\": target,\n",
    "            \"Top5_Peers_MLE\": str(neighbors_5[target][\"top_ids\"]),\n",
    "            \"Top10_Peers_MLE\": str(neighbors_10[target][\"top_ids\"])\n",
    "        })\n",
    "\n",
    "peers_table = pd.DataFrame(peer_summary)\n",
    "save_csv(peers_table, \"pca_mle_peers.csv\")\n",
    "print(\"Step 2 Output Saved: pca_mle_peers.csv\")\n",
    "\n",
    "# Display top-5 peers for each target\n",
    "for target in active_targets:\n",
    "    if target in neighbors_5:\n",
    "        print(f\"Target {target} Top-5 Peers: {neighbors_5[target]['top_ids']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ccdb7",
   "metadata": {},
   "source": [
    "## Step 3: Reduced Dimensional Space (Top 5 Neighbors)\n",
    "\n",
    "Document the latent peer space and construct user feature vectors in the reduced dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49dc11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved CSV: tables/pca_mle_reduced_space_top5.csv\n",
      "Step 3 Output Saved: pca_mle_reduced_space_top5.csv\n",
      "    Saved CSV: tables/pca_mle_user_reduced_vectors_top5.csv\n",
      "Step 3 (extra) Output Saved: pca_mle_user_reduced_vectors_top5.csv\n",
      "   TargetItem  Peer_Rank  Peer_ItemID  Latent_Similarity Space_Type\n",
      "0        1556          1          628           0.650902   Top5_MLE\n",
      "1        1556          2         2167           0.643302   Top5_MLE\n",
      "2        1556          3         1722           0.611007   Top5_MLE\n",
      "3        1556          4         1917           0.578528   Top5_MLE\n",
      "4        1556          5         1801           0.562561   Top5_MLE\n"
     ]
    }
   ],
   "source": [
    "# Build reduced space table\n",
    "reduced_space_5 = []\n",
    "for target in active_targets:\n",
    "    if target not in neighbors_5:\n",
    "        continue\n",
    "    peer_list = neighbors_5[target]['top_ids'][:5]\n",
    "    similarity_vals = neighbors_5[target]['sim_series']\n",
    "\n",
    "    for position, peer_id in enumerate(peer_list, 1):\n",
    "        reduced_space_5.append({\n",
    "            'TargetItem': target,\n",
    "            'Peer_Rank': position,\n",
    "            'Peer_ItemID': peer_id,\n",
    "            'Latent_Similarity': float(similarity_vals[peer_id]),\n",
    "            'Space_Type': 'Top5_MLE'\n",
    "        })\n",
    "\n",
    "reduced_5_df = pd.DataFrame(reduced_space_5)\n",
    "save_csv(reduced_5_df, 'pca_mle_reduced_space_top5.csv')\n",
    "print(\"Step 3 Output Saved: pca_mle_reduced_space_top5.csv\")\n",
    "\n",
    "# Build user feature vectors in reduced space\n",
    "user_features_5 = []\n",
    "for target in active_targets:\n",
    "    if target not in neighbors_5:\n",
    "        continue\n",
    "    peer_items = neighbors_5[target]['top_ids'][:5]\n",
    "\n",
    "    for user in users_with_missing:\n",
    "        if user not in ui_centered.index:\n",
    "            continue\n",
    "        \n",
    "        # Extract user's ratings on peer items\n",
    "        user_vector = ui_centered.loc[user, peer_items].values\n",
    "        feature_dict = {'UserID': user, 'TargetItem': target}\n",
    "        \n",
    "        for idx, peer in enumerate(peer_items, 1):\n",
    "            feature_dict[f'Peer{idx}_{peer}'] = user_vector[idx-1]\n",
    "        \n",
    "        user_features_5.append(feature_dict)\n",
    "\n",
    "user_vec_5_df = pd.DataFrame(user_features_5)\n",
    "save_csv(user_vec_5_df, 'pca_mle_user_reduced_vectors_top5.csv')\n",
    "print(\"Step 3 (extra) Output Saved: pca_mle_user_reduced_vectors_top5.csv\")\n",
    "\n",
    "print(reduced_5_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7fbcf",
   "metadata": {},
   "source": [
    "## Step 4: Rating Predictions Using Top 5 Neighbors\n",
    "\n",
    "Generate rating predictions using similarity-weighted averaging over the top 5 latent neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42d1af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved CSV: tables/pca_mle_preds_top5.csv\n",
      "Step 4 Output Saved: pca_mle_preds_top5.csv\n",
      "   UserID  ItemID  Pred_MLE_Top5   Status\n",
      "0       1    1556       1.919431  Missing\n",
      "1       1    1499       1.986574  Missing\n",
      "2       2    1556       1.919431  Missing\n",
      "3       2    1499       2.059603  Missing\n",
      "4       3    1556       1.919431  Missing\n"
     ]
    }
   ],
   "source": [
    "predictions_5 = []\n",
    "\n",
    "for user in users_with_missing:\n",
    "    if user not in ui_matrix.index:\n",
    "        continue\n",
    "\n",
    "    for target in active_targets:\n",
    "        if target not in neighbors_5:\n",
    "            continue\n",
    "\n",
    "        # Check if rating exists\n",
    "        rating_status = \"Existing\" if pd.notna(ui_matrix.loc[user, target]) else \"Missing\"\n",
    "\n",
    "        peer_items = neighbors_5[target]['top_ids'][:5]\n",
    "        similarity_weights = neighbors_5[target]['sim_series']\n",
    "\n",
    "        # Compute weighted prediction\n",
    "        numerator = 0.0\n",
    "        denominator = 0.0\n",
    "\n",
    "        for peer in peer_items:\n",
    "            user_rating = ui_centered.loc[user, peer]\n",
    "            if pd.notna(user_rating):\n",
    "                weight = float(similarity_weights[peer])\n",
    "                numerator += weight * float(user_rating)\n",
    "                denominator += abs(weight)\n",
    "\n",
    "        # Add back the item mean\n",
    "        baseline = float(item_avg[target]) if target in item_avg.index else 0.0\n",
    "        predicted_rating = baseline + (numerator / denominator) if denominator != 0 else baseline\n",
    "\n",
    "        predictions_5.append({\n",
    "            'UserID': user, \n",
    "            'ItemID': target, \n",
    "            'Pred_MLE_Top5': predicted_rating, \n",
    "            'Status': rating_status\n",
    "        })\n",
    "\n",
    "predictions_5_df = pd.DataFrame(predictions_5)\n",
    "save_csv(predictions_5_df, \"pca_mle_preds_top5.csv\")\n",
    "print(\"Step 4 Output Saved: pca_mle_preds_top5.csv\")\n",
    "print(predictions_5_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106691a",
   "metadata": {},
   "source": [
    "## Step 5: Reduced Dimensional Space (Top 10 Neighbors)\n",
    "\n",
    "Expand the latent space to include top 10 neighbors and generate corresponding user feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de8995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved CSV: tables/pca_mle_reduced_space_top10.csv\n",
      "Step 5 (extra) Output Saved: pca_mle_reduced_space_top10.csv\n",
      "    Saved CSV: tables/pca_mle_user_reduced_vectors_top10.csv\n",
      "Step 5 (extra) Output Saved: pca_mle_user_reduced_vectors_top10.csv\n",
      "   TargetItem  Peer_Rank  Peer_ItemID  Latent_Similarity Space_Type\n",
      "0        1556          1          628           0.650902  Top10_MLE\n",
      "1        1556          2         2167           0.643302  Top10_MLE\n",
      "2        1556          3         1722           0.611007  Top10_MLE\n",
      "3        1556          4         1917           0.578528  Top10_MLE\n",
      "4        1556          5         1801           0.562561  Top10_MLE\n",
      "5        1556          6          748           0.550894  Top10_MLE\n",
      "6        1556          7         5481           0.525898  Top10_MLE\n",
      "7        1556          8          196           0.524533  Top10_MLE\n",
      "8        1556          9          160           0.517657  Top10_MLE\n",
      "9        1556         10         4643           0.499900  Top10_MLE\n"
     ]
    }
   ],
   "source": [
    "# Build reduced space table for top 10\n",
    "reduced_space_10 = []\n",
    "for target in active_targets:\n",
    "    if target not in neighbors_10:\n",
    "        continue\n",
    "    peer_list = neighbors_10[target]['top_ids'][:10]\n",
    "    similarity_vals = neighbors_10[target]['sim_series']\n",
    "\n",
    "    for position, peer_id in enumerate(peer_list, 1):\n",
    "        reduced_space_10.append({\n",
    "            'TargetItem': target,\n",
    "            'Peer_Rank': position,\n",
    "            'Peer_ItemID': peer_id,\n",
    "            'Latent_Similarity': float(similarity_vals[peer_id]),\n",
    "            'Space_Type': 'Top10_MLE'\n",
    "        })\n",
    "\n",
    "reduced_10_df = pd.DataFrame(reduced_space_10)\n",
    "save_csv(reduced_10_df, 'pca_mle_reduced_space_top10.csv')\n",
    "print(\"Step 5 (extra) Output Saved: pca_mle_reduced_space_top10.csv\")\n",
    "\n",
    "\n",
    "# Build user feature vectors with 10 dimensions\n",
    "user_features_10 = []\n",
    "for target in active_targets:\n",
    "    if target not in neighbors_10:\n",
    "        continue\n",
    "    peer_items = neighbors_10[target]['top_ids'][:10]\n",
    "\n",
    "    for user in users_with_missing:\n",
    "        if user not in ui_centered.index:\n",
    "            continue\n",
    "        \n",
    "        # Extract user's ratings on peer items\n",
    "        user_vector = ui_centered.loc[user, peer_items].values\n",
    "        feature_dict = {'UserID': user, 'TargetItem': target}\n",
    "        \n",
    "        for idx, peer in enumerate(peer_items, 1):\n",
    "            feature_dict[f'Peer{idx}_{peer}'] = user_vector[idx-1]\n",
    "        \n",
    "        user_features_10.append(feature_dict)\n",
    "\n",
    "user_vec_10_df = pd.DataFrame(user_features_10)\n",
    "save_csv(user_vec_10_df, 'pca_mle_user_reduced_vectors_top10.csv')\n",
    "print(\"Step 5 (extra) Output Saved: pca_mle_user_reduced_vectors_top10.csv\")\n",
    "\n",
    "print(reduced_10_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858974a8",
   "metadata": {},
   "source": [
    "## Step 6: Rating Predictions Using Top 10 Neighbors\n",
    "\n",
    "Generate predictions with expanded neighborhood for potentially improved accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a041ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Saved CSV: tables/pca_mle_preds_top10.csv\n",
      "Step 6 Output Saved: pca_mle_preds_top10.csv\n",
      "   UserID  ItemID  Pred_MLE_Top10   Status\n",
      "0       1    1556        1.919431  Missing\n",
      "1       1    1499        1.986574  Missing\n",
      "2       2    1556        1.919431  Missing\n",
      "3       2    1499        2.059603  Missing\n",
      "4       3    1556        1.919431  Missing\n",
      "5       3    1499        2.059603  Missing\n",
      "6       4    1556        1.919431  Missing\n",
      "7       4    1499        2.301512  Missing\n",
      "8       5    1556        1.919431  Missing\n",
      "9       5    1499        2.059603  Missing\n"
     ]
    }
   ],
   "source": [
    "predictions_10 = []\n",
    "\n",
    "for user in users_with_missing:\n",
    "    if user not in ui_matrix.index:\n",
    "        continue\n",
    "\n",
    "    for target in active_targets:\n",
    "        if target not in neighbors_10:\n",
    "            continue\n",
    "\n",
    "        # Determine rating status\n",
    "        rating_status = \"Existing\" if pd.notna(ui_matrix.loc[user, target]) else \"Missing\"\n",
    "\n",
    "        peer_items = neighbors_10[target]['top_ids'][:10]\n",
    "        similarity_weights = neighbors_10[target]['sim_series']\n",
    "\n",
    "        # Calculate weighted average\n",
    "        numerator = 0.0\n",
    "        denominator = 0.0\n",
    "\n",
    "        for peer in peer_items:\n",
    "            user_rating = ui_centered.loc[user, peer]\n",
    "            if pd.notna(user_rating):\n",
    "                weight = float(similarity_weights[peer])\n",
    "                numerator += weight * float(user_rating)\n",
    "                denominator += abs(weight)\n",
    "\n",
    "        # Add item baseline\n",
    "        baseline = float(item_avg[target]) if target in item_avg.index else 0.0\n",
    "        predicted_rating = baseline + (numerator / denominator) if denominator != 0 else baseline\n",
    "\n",
    "        predictions_10.append({\n",
    "            'UserID': user, \n",
    "            'ItemID': target, \n",
    "            'Pred_MLE_Top10': predicted_rating, \n",
    "            'Status': rating_status\n",
    "        })\n",
    "\n",
    "predictions_10_df = pd.DataFrame(predictions_10)\n",
    "save_csv(predictions_10_df, \"pca_mle_preds_top10.csv\")\n",
    "print(\"Step 6 Output Saved: pca_mle_preds_top10.csv\")\n",
    "print(predictions_10_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371c410",
   "metadata": {},
   "source": [
    "## Step 7/8/9: Comparison Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c593a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 - Reduced Dimensional Space (Top 5 Peers):\n",
      "   TargetItem  Peer_Rank  Peer_ItemID  Latent_Similarity Space_Type\n",
      "0        1556          1          628           0.650902   Top5_MLE\n",
      "1        1556          2         2167           0.643302   Top5_MLE\n",
      "2        1556          3         1722           0.611007   Top5_MLE\n",
      "3        1556          4         1917           0.578528   Top5_MLE\n",
      "4        1556          5         1801           0.562561   Top5_MLE\n",
      "5        1499          1         2804           0.628761   Top5_MLE\n",
      "6        1499          2         1296           0.610479   Top5_MLE\n",
      "7        1499          3          420           0.587618   Top5_MLE\n",
      "8        1499          4         3623           0.542076   Top5_MLE\n",
      "9        1499          5         4855           0.539109   Top5_MLE\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Step 6 - Rating Predictions (Top 10 Peers):\n",
      "    UserID  ItemID  Pred_MLE_Top10   Status\n",
      "0        1    1556        1.919431  Missing\n",
      "1        1    1499        1.986574  Missing\n",
      "2        2    1556        1.919431  Missing\n",
      "3        2    1499        2.059603  Missing\n",
      "4        3    1556        1.919431  Missing\n",
      "5        3    1499        2.059603  Missing\n",
      "6        4    1556        1.919431  Missing\n",
      "7        4    1499        2.301512  Missing\n",
      "8        5    1556        1.919431  Missing\n",
      "9        5    1499        2.059603  Missing\n",
      "10       7    1556        1.919431  Missing\n",
      "11       7    1499        2.059603  Missing\n",
      "12       8    1556        1.919431  Missing\n",
      "13       8    1499        2.059603  Missing\n",
      "14       9    1556        1.919431  Missing\n",
      "15       9    1499        2.059603  Missing\n",
      "16      10    1556        1.919431  Missing\n",
      "17      10    1499        2.059603  Missing\n",
      "18      11    1556        3.141164  Missing\n",
      "19      11    1499        2.059603  Missing\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Comparison Analysis:\n",
      "Number of peer items in reduced space (Step 3): 10\n",
      "Number of predictions made (Step 6): 192658\n",
      "\n",
      "Step 3 uses Top5_MLE for dimensionality reduction\n",
      "Step 6 predictions are based on Top 10 neighbors\n",
      "\n",
      "Average prediction value (Step 6): 1.9905\n",
      "Average latent similarity (Step 3): 0.5954\n",
      "    Saved CSV: tables/pca_mle_comparison.csv\n",
      "\n",
      "Step 7 Output Saved: pca_mle_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Display the reduced dimensional space from Step 3 (Top 5)\n",
    "print(\"Step 3 - Reduced Dimensional Space (Top 5 Peers):\")\n",
    "print(reduced_5_df)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Display the prediction results from Step 6 (Top 10)\n",
    "print(\"Step 6 - Rating Predictions (Top 10 Peers):\")\n",
    "print(predictions_10_df.head(20))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Comparison Analysis\n",
    "print(\"Comparison Analysis:\")\n",
    "print(f\"Number of peer items in reduced space (Step 3): {len(reduced_5_df)}\")\n",
    "print(f\"Number of predictions made (Step 6): {len(predictions_10_df)}\")\n",
    "print(f\"\\nStep 3 uses {reduced_5_df['Space_Type'].iloc[0]} for dimensionality reduction\")\n",
    "print(f\"Step 6 predictions are based on Top 10 neighbors\")\n",
    "\n",
    "\n",
    "# Save comparison summary\n",
    "comparison_summary = {\n",
    "    'Step3_Peers_Count': len(reduced_5_df),\n",
    "    'Step6_Predictions_Count': len(predictions_10_df),\n",
    "    'Step3_Avg_Similarity': reduced_5_df['Latent_Similarity'].mean(),\n",
    "    'Step6_Avg_Prediction': predictions_10_df['Pred_MLE_Top10'].mean()\n",
    "}\n",
    "summary_df = pd.DataFrame([comparison_summary])\n",
    "print(f\"\\nAverage prediction value (Step 6): {predictions_10_df['Pred_MLE_Top10'].mean():.4f}\")\n",
    "print(f\"Average latent similarity (Step 3): {reduced_5_df['Latent_Similarity'].mean():.4f}\")\n",
    "\n",
    "save_csv(summary_df, \"pca_mle_comparison.csv\")\n",
    "print(\"\\nStep 7 Output Saved: pca_mle_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df966c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found requested table at: ..\\results\\tables\\3.2.9_predictions_target_1499.csv\n",
      " Found requested table at: ..\\results\\tables\\3.2.9_predictions_target_1556.csv\n",
      "    Saved CSV: tables/pca_mle_method_comparison.csv\n",
      "Step 8 Output Saved: pca_mle_method_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "STEP 8: Comparison of Linear Regression vs PCA MLE Top-5 Predictions\n",
      "================================================================================\n",
      "\n",
      "First 10 comparisons:\n",
      "   UserID  ItemID  LinearRegression_Pred  PCA_MLE_Pred      Diff   AbsDiff\n",
      "0       1  1499.0               2.059603      1.986574  0.073028  0.073028\n",
      "1       2  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "2       3  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "3       4  1499.0               2.059603      2.301512 -0.241909  0.241909\n",
      "4       5  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "5       7  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "6       8  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "7       9  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "8      10  1499.0               2.059603      2.059603  0.000000  0.000000\n",
      "9      11  1499.0               2.526965      2.059603  0.467363  0.467363\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "Total predictions compared: 192658\n",
      "\n",
      "Linear Regression Method:\n",
      "  Mean Prediction: 1.989515\n",
      "  Std Deviation:   0.079471\n",
      "\n",
      "PCA MLE Method:\n",
      "  Mean Prediction: 1.989680\n",
      "  Std Deviation:   0.221126\n",
      "\n",
      "Difference Analysis:\n",
      "  Mean Absolute Difference: 0.038889\n",
      "  Max Absolute Difference:  3.073028\n",
      "  Min Absolute Difference:  0.000000\n",
      "  Std Dev of Differences:   0.207828\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Compare Linear Regression Method with PCA MLE Method\n",
    "\n",
    "# Load linear regression predictions from Task 9 (from results folder)\n",
    "lr_pred_1499 = load_data(table_name='3.2.9_predictions_target_1499.csv')\n",
    "lr_pred_1556 = load_data(table_name='3.2.9_predictions_target_1556.csv')\n",
    "\n",
    "# Combine both target items\n",
    "lr_predictions = pd.concat([lr_pred_1499, lr_pred_1556], ignore_index=True)\n",
    "\n",
    "# Rename columns to match PCA naming convention\n",
    "lr_predictions.rename(columns={\n",
    "    'userId': 'UserID',\n",
    "    'movieId': 'ItemID',\n",
    "    'predicted_rating_final': 'Predicted_Rating'  # Fixed: removed leading space\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with PCA MLE predictions from Step 4\n",
    "comparison_df = pd.merge(\n",
    "    lr_predictions[['UserID', 'ItemID', 'Predicted_Rating']],\n",
    "    predictions_5_df[['UserID', 'ItemID', 'Pred_MLE_Top5']],\n",
    "    on=['UserID', 'ItemID'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "comparison_df.rename(columns={\n",
    "    'Predicted_Rating': 'LinearRegression_Pred',\n",
    "    'Pred_MLE_Top5': 'PCA_MLE_Pred'\n",
    "}, inplace=True)\n",
    "\n",
    "# Calculate differences\n",
    "comparison_df['Diff'] = comparison_df['LinearRegression_Pred'] - comparison_df['PCA_MLE_Pred']\n",
    "comparison_df['AbsDiff'] = comparison_df['Diff'].abs()\n",
    "\n",
    "# Save comparison results\n",
    "save_csv(comparison_df, \"pca_mle_method_comparison.csv\")\n",
    "print(\"Step 8 Output Saved: pca_mle_method_comparison.csv\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: Comparison of Linear Regression vs PCA MLE Top-5 Predictions\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFirst 10 comparisons:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Total predictions compared: {len(comparison_df)}\")\n",
    "print(f\"\\nLinear Regression Method:\")\n",
    "print(f\"  Mean Prediction: {comparison_df['LinearRegression_Pred'].mean():.6f}\")\n",
    "print(f\"  Std Deviation:   {comparison_df['LinearRegression_Pred'].std():.6f}\")\n",
    "print(f\"\\nPCA MLE Method:\")\n",
    "print(f\"  Mean Prediction: {comparison_df['PCA_MLE_Pred'].mean():.6f}\")\n",
    "print(f\"  Std Deviation:   {comparison_df['PCA_MLE_Pred'].std():.6f}\")\n",
    "print(f\"\\nDifference Analysis:\")\n",
    "print(f\"  Mean Absolute Difference: {comparison_df['AbsDiff'].mean():.6f}\")\n",
    "print(f\"  Max Absolute Difference:  {comparison_df['AbsDiff'].max():.6f}\")\n",
    "print(f\"  Min Absolute Difference:  {comparison_df['AbsDiff'].min():.6f}\")\n",
    "print(f\"  Std Dev of Differences:   {comparison_df['Diff'].std():.6f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4015765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found requested table at: ..\\results\\tables\\3.2.11_predictions_target_1499_top10.csv\n",
      " Found requested table at: ..\\results\\tables\\3.2.11_predictions_target_1556_top10.csv\n",
      "    Saved CSV: tables/pca_mle_method_comparison_top10.csv\n",
      "Step 9 Output Saved: pca_mle_method_comparison_top10.csv\n",
      "\n",
      "================================================================================\n",
      "STEP 9: Comparison of Linear Regression Top-10 vs PCA MLE Top-10 Predictions\n",
      "================================================================================\n",
      "\n",
      "First 10 comparisons:\n",
      "   UserID  ItemID  LinearRegression_Top10_Pred  PCA_MLE_Top10_Pred      Diff  \\\n",
      "0       1  1499.0                     2.059603            1.986574  0.073028   \n",
      "1       2  1499.0                     2.059603            2.059603  0.000000   \n",
      "2       3  1499.0                     2.059603            2.059603  0.000000   \n",
      "3       4  1499.0                     2.059603            2.301512 -0.241909   \n",
      "4       5  1499.0                     2.059603            2.059603  0.000000   \n",
      "5       7  1499.0                     2.059603            2.059603  0.000000   \n",
      "6       8  1499.0                     2.059603            2.059603  0.000000   \n",
      "7       9  1499.0                     2.059603            2.059603  0.000000   \n",
      "8      10  1499.0                     2.059603            2.059603  0.000000   \n",
      "9      11  1499.0                     2.321055            2.059603  0.261453   \n",
      "\n",
      "    AbsDiff  \n",
      "0  0.073028  \n",
      "1  0.000000  \n",
      "2  0.000000  \n",
      "3  0.241909  \n",
      "4  0.000000  \n",
      "5  0.000000  \n",
      "6  0.000000  \n",
      "7  0.000000  \n",
      "8  0.000000  \n",
      "9  0.261453  \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Statistical Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "Total predictions compared: 192658\n",
      "\n",
      "Linear Regression Top-10 Method:\n",
      "  Mean Prediction: 1.989515\n",
      "  Std Deviation:   0.074593\n",
      "\n",
      "PCA MLE Top-10 Method:\n",
      "  Mean Prediction: 1.990532\n",
      "  Std Deviation:   0.312306\n",
      "\n",
      "Difference Analysis:\n",
      "  Mean Absolute Difference: 0.078930\n",
      "  Max Absolute Difference:  3.073028\n",
      "  Min Absolute Difference:  0.000000\n",
      "  Std Dev of Differences:   0.302644\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Compare Linear Regression Top-10 with PCA MLE Top-10\n",
    "\n",
    "# Load linear regression Top-10 predictions\n",
    "lr_pred_1499_top10 = load_data(table_name='3.2.11_predictions_target_1499_top10.csv')\n",
    "lr_pred_1556_top10 = load_data(table_name='3.2.11_predictions_target_1556_top10.csv')\n",
    "\n",
    "# Combine both target items\n",
    "lr_predictions_top10 = pd.concat([lr_pred_1499_top10, lr_pred_1556_top10], ignore_index=True)\n",
    "\n",
    "# Rename columns to match PCA naming convention\n",
    "lr_predictions_top10.rename(columns={\n",
    "    'userId': 'UserID',\n",
    "    'movieId': 'ItemID',\n",
    "    'predicted_rating_final': 'Predicted_Rating'\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge with PCA MLE Top-10 predictions from Step 6\n",
    "comparison_df = pd.merge(\n",
    "    lr_predictions_top10[['UserID', 'ItemID', 'Predicted_Rating']],\n",
    "    predictions_10_df[['UserID', 'ItemID', 'Pred_MLE_Top10']],\n",
    "    on=['UserID', 'ItemID'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "comparison_df.rename(columns={\n",
    "    'Predicted_Rating': 'LinearRegression_Top10_Pred',\n",
    "    'Pred_MLE_Top10': 'PCA_MLE_Top10_Pred'\n",
    "}, inplace=True)\n",
    "\n",
    "# Calculate differences\n",
    "comparison_df['Diff'] = comparison_df['LinearRegression_Top10_Pred'] - comparison_df['PCA_MLE_Top10_Pred']\n",
    "comparison_df['AbsDiff'] = comparison_df['Diff'].abs()\n",
    "\n",
    "# Save comparison results\n",
    "save_csv(comparison_df, \"pca_mle_method_comparison_top10.csv\")\n",
    "print(\"Step 9 Output Saved: pca_mle_method_comparison_top10.csv\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: Comparison of Linear Regression Top-10 vs PCA MLE Top-10 Predictions\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFirst 10 comparisons:\")\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Total predictions compared: {len(comparison_df)}\")\n",
    "print(f\"\\nLinear Regression Top-10 Method:\")\n",
    "print(f\"  Mean Prediction: {comparison_df['LinearRegression_Top10_Pred'].mean():.6f}\")\n",
    "print(f\"  Std Deviation:   {comparison_df['LinearRegression_Top10_Pred'].std():.6f}\")\n",
    "print(f\"\\nPCA MLE Top-10 Method:\")\n",
    "print(f\"  Mean Prediction: {comparison_df['PCA_MLE_Top10_Pred'].mean():.6f}\")\n",
    "print(f\"  Std Deviation:   {comparison_df['PCA_MLE_Top10_Pred'].std():.6f}\")\n",
    "print(f\"\\nDifference Analysis:\")\n",
    "print(f\"  Mean Absolute Difference: {comparison_df['AbsDiff'].mean():.6f}\")\n",
    "print(f\"  Max Absolute Difference:  {comparison_df['AbsDiff'].max():.6f}\")\n",
    "print(f\"  Min Absolute Difference:  {comparison_df['AbsDiff'].min():.6f}\")\n",
    "print(f\"  Std Dev of Differences:   {comparison_df['Diff'].std():.6f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22109fa1",
   "metadata": {},
   "source": [
    "# Statistical Analysis\n",
    "This notebook loads the dataset, calculates statistics, and selects target users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb057a",
   "metadata": {},
   "source": [
    "Eyad Medhat 221100279\n",
    "/ Hady Aly 221101190\n",
    "/ Mohamed Mahfouz 221101743\n",
    "/ Omar Mady 221100745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52f9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found cached sample at: ..\\data\\ml-20m\\ratings_cleaned_sampled.csv\n",
      "Loaded DataFrame with shape: (1000000, 3)\n",
      "   userId  movieId  rating\n",
      "0   49400     4011       5\n",
      "1  118685      786       3\n",
      "2   80510     1247       3\n",
      "3  124963     1721       1\n",
      "4   31031     1982       4\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "df = load_and_sample_data()\n",
    "if df is not None:\n",
    "    print(f\"Loaded DataFrame with shape: {df.shape}\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Failed to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab47ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Users: 96345\n",
      "Current Items: 1000\n",
      "Current Interactions (Ratings): 1000000\n"
     ]
    }
   ],
   "source": [
    "current_users = df['userId'].nunique()\n",
    "current_items = df['movieId'].nunique()\n",
    "current_interactions = len(df)\n",
    "\n",
    "print(f\"Current Users: {current_users}\")\n",
    "print(f\"Current Items: {current_items}\")\n",
    "print(f\"Current Interactions (Ratings): {current_interactions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting manual loop for Group: 'userId' -> Target: 'rating'...\n"
     ]
    }
   ],
   "source": [
    "user_stats_df = Mean(df, group_col='userId', target_col='rating')\n",
    "\n",
    "\n",
    "print(\"Number of ratings per user (rating_count_per_user) calculated.\")\n",
    "print(user_stats_df.head())\n",
    "\n",
    "save_csv(user_stats_df,'stats_per_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_stats_df = Mean(df, group_col='movieId', target_col='rating')\n",
    "\n",
    "\n",
    "print(\"Number of ratings per item (stats_per_item) calculated.\")\n",
    "print(item_stats_df.head())\n",
    "\n",
    "save_csv(item_stats_df,'stats_per_item')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c6998",
   "metadata": {},
   "source": [
    "# Item Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c4552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ascendingly order the total number of ratings per item\n",
    "sorted_counts = item_stats_df['rating_count_per_movie'].sort_values(ascending=True).values\n",
    "\n",
    "# Plot the distribution per item\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(sorted_counts, color='blue', linewidth=1.5)\n",
    "\n",
    "# Logarithmic scale to visualize the long-tail distribution\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_title('Distribution of Ratings per Item (Log Scale)')\n",
    "ax.set_xlabel('Items (Sorted by Popularity)')\n",
    "ax.set_ylabel('Number of Ratings (Log Scale)')\n",
    "ax.grid(True, which=\"both\", linestyle='--', alpha=0.5)\n",
    "\n",
    "save_plot(fig, 'item_rating_distribution_ascending')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sort the DataFrame by the correct column name\n",
    "sorted_counts = item_stats_df.sort_values(by='rating_count_per_movie', ascending=True)\n",
    "\n",
    "# Histogram: Frequency of Rating Counts\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 2. Plot using the SORTED DataFrame and CORRECT column name\n",
    "plt.hist(sorted_counts['rating_count_per_movie'], bins=50, edgecolor='black', color='blue', log=True)\n",
    "\n",
    "plt.title('Distribution of Rating Counts (Histogram)')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Items (Frequency)')\n",
    "\n",
    "save_plot(fig, 'item_rating_distribution_ascending_hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24dfb7",
   "metadata": {},
   "source": [
    "# Item Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sort items by Average Rating (Manual-friendly approach)\n",
    "# We already have item_stats_df from Section 1.6\n",
    "item_stats_sorted = item_stats_df.sort_values(by='mean_rating_per_movie', ascending=True).reset_index(drop=True)\n",
    "\n",
    "total_items = len(item_stats_sorted)\n",
    "\n",
    "# 2. Define the index boundaries based on percentages\n",
    "# Req: <1%, 1-5%, 5-10%, 10-20%, 20-30%, 30-40%, 40-50%, 50-60%, 60-70%, 70-100%\n",
    "cuts = [0, 0.01, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 1.0]\n",
    "group_labels = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'G10']\n",
    "\n",
    "# 3. Manually assign groups based on row position (index)\n",
    "item_groups = []\n",
    "\n",
    "# Loop through the sorted dataframe\n",
    "for index, row in item_stats_sorted.iterrows():\n",
    "    # Calculate relative position (0.0 to 1.0)\n",
    "    position = (index + 1) / total_items\n",
    "    \n",
    "    # Determine group\n",
    "    assigned_group = \"\"\n",
    "    for i in range(len(cuts) - 1):\n",
    "        if position <= cuts[i+1]:\n",
    "            assigned_group = group_labels[i]\n",
    "            break\n",
    "            \n",
    "    item_groups.append(assigned_group)\n",
    "\n",
    "item_stats_sorted['group'] = item_groups\n",
    "\n",
    "print(\"Point 1.8 Complete: Items grouped by percentile position manually.\")\n",
    "print(item_stats_sorted[['movieId', 'mean_rating_per_movie', 'group']].head())\n",
    "print(item_stats_sorted[['movieId', 'mean_rating_per_movie', 'group']].tail())\n",
    "\n",
    "save_csv(item_stats_sorted, 'grouped_items.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f260a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary\n",
    "group_sums = {label: 0 for label in group_labels}\n",
    "\n",
    "# Manual Loop to sum ratings per group\n",
    "for index, row in item_stats_sorted.iterrows():\n",
    "    g = row['group']\n",
    "    n_ratings = row['rating_count_per_movie']\n",
    "    group_sums[g] += n_ratings\n",
    "\n",
    "# Convert to DataFrame for easier printing/plotting\n",
    "group_counts_df = pd.DataFrame(list(group_sums.items()), columns=['group', 'total_ratings'])\n",
    "\n",
    "# Order ascendingly as required\n",
    "group_counts_sorted = group_counts_df.sort_values(by='total_ratings', ascending=True)\n",
    "\n",
    "print(\"Total ratings per group\")\n",
    "print(group_counts_sorted)\n",
    "\n",
    "\n",
    "save_csv(group_counts_sorted,'movie_count_per_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot 1: Unsorted Groups ---\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "group_counts_df.plot(kind='bar', color='skyblue', edgecolor='black', log=True, ax=plt.gca())\n",
    "\n",
    "plt.title('Distribution of Total Ratings per Group (Log Scale)')\n",
    "plt.xlabel('Group (G1-G10)')\n",
    "plt.ylabel('Total Number of Ratings (Log Scale)')\n",
    "\n",
    "# Force x-axis labels to match the group names\n",
    "# rot=0 makes them horizontal for readability\n",
    "plt.xticks(range(len(group_counts_df)), group_counts_df['group'], rotation=0) \n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5, which='both')\n",
    "save_plot(fig, 'group_counts_hist_not_sorted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Plot 2: Sorted Groups ---\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "group_counts_sorted.plot(kind='bar', color='skyblue', edgecolor='black', log=True, ax=plt.gca())\n",
    "\n",
    "plt.title('Distribution of Total Ratings per Group (Sorted, Log Scale)')\n",
    "plt.xlabel('Group (G1-G10)')\n",
    "plt.ylabel('Total Number of Ratings (Log Scale)')\n",
    "\n",
    "# Force x-axis labels to match the group names of the SORTED data\n",
    "plt.xticks(range(len(group_counts_sorted)), group_counts_sorted['group'], rotation=0)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5, which='both')\n",
    "save_plot(fig, 'group_counts_hist_sorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. User Selection ---\n",
    "if item_stats_df is not None and user_stats_df is not None:\n",
    "    \n",
    "    # Recalculate percentages if needed (or ensure they exist)\n",
    "    # We recalculate to be safe as loaded CSV might be old format\n",
    "    total_items_count = len(item_stats_df)\n",
    "    user_stats_df['pct_rated'] = (user_stats_df['rating_count_per_user'] / total_items_count) * 100\n",
    "    \n",
    "    print(f\"Total Items: {total_items_count}\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "    selected_data = []\n",
    "\n",
    "    # Random Selection Logic\n",
    "    # U1: < 2%\n",
    "    u1_id = get_random_user_and_check(\n",
    "        df=user_stats_df,\n",
    "        storage_list=selected_data,\n",
    "        condition_mask=(user_stats_df['pct_rated'] < 2.0),\n",
    "        label=\"U1 (Sparse)\",\n",
    "        condition_text=\"< 2%\",\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # U2: 2% - 5%\n",
    "    u2_id = get_random_user_and_check(\n",
    "        df=user_stats_df,\n",
    "        storage_list=selected_data,\n",
    "        condition_mask=(user_stats_df['pct_rated'] >= 2.0) & (user_stats_df['pct_rated'] < 5.0),\n",
    "        label=\"U2 (Medium)\",\n",
    "        condition_text=\"2% - 5%\",\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # U3: 5% - 10%\n",
    "    u3_id = get_random_user_and_check(\n",
    "        df=user_stats_df,\n",
    "        storage_list=selected_data,\n",
    "        condition_mask=(user_stats_df['pct_rated'] >= 5.0) & (user_stats_df['pct_rated'] < 10.0),\n",
    "        label=\"U3 (Dense)\",\n",
    "        condition_text=\"5% - 10%\",\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal Selected IDs for Random Targets:\")\n",
    "    print(f\"U1: {u1_id}, U2: {u2_id}, U3: {u3_id}\")\n",
    "\n",
    "    # Save Selected Users\n",
    "    target_users_df = pd.DataFrame(selected_data)\n",
    "    save_csv(target_users_df, 'Selected_Target_Users.csv')\n",
    "else:\n",
    "    print(\"Skipping selection: Missing required stats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the DataFrame of the lowest rated items\n",
    "# NOTE: change 'avg_rating' to your actual rating column name if different\n",
    "lowest_rated_df = (\n",
    "    item_stats_df\n",
    "    .sort_values(by='mean_rating_per_movie', ascending=True)\n",
    "    .head(2)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "if lowest_rated_df is not None and len(lowest_rated_df) >= 2:\n",
    "    # 2. Extract IDs for further use (if needed)\n",
    "    I1 = lowest_rated_df.iloc[0]['movieId']\n",
    "    I2 = lowest_rated_df.iloc[1]['movieId']\n",
    "    print(f\"Target Item 1: {I1}\")\n",
    "    print(f\"Target Item 2: {I2}\")\n",
    "\n",
    "    # 3. Save to CSV\n",
    "    # This will save to E:\\grad_year_sem1\\irs_project\\SECTION1_DimensionalityReduction\\results\\tables\\lowest_two_rateditems.csv\n",
    "    save_csv(lowest_rated_df, 'lowest_two_rateditems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d939cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure main dataframe is loaded\n",
    "if 'df' not in locals() or df is None:\n",
    "    print(\"Main dataframe 'df' not found. Loading...\")\n",
    "    # Adjust path if needed for notebook location\n",
    "    import os\n",
    "    if os.path.exists(os.path.join('..', 'data', 'ml-20m', 'ratings_cleaned.csv')):\n",
    "         df = load_data(os.path.join('..', 'data', 'ml-20m', 'ratings_cleaned.csv'))\n",
    "    else:\n",
    "         df = load_data(os.path.join('ml-20m', 'ratings_cleaned.csv'))\n",
    "\n",
    "# Load Target Users\n",
    "try:\n",
    "    users_csv_path = r'../results/tables/Selected_Target_Users.csv'\n",
    "    users_df = pd.read_csv(users_csv_path)\n",
    "    target_user_ids = users_df['UserId'].tolist()\n",
    "    print(f\"Loaded {len(target_user_ids)} Target Users: {target_user_ids}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading target users: {e}\")\n",
    "    target_user_ids = []\n",
    "\n",
    "# Load Target Items\n",
    "try:\n",
    "    items_csv_path = r'../results/tables/lowest_two_rateditems.csv'\n",
    "    items_df = pd.read_csv(items_csv_path)\n",
    "    target_item_ids = items_df['movieId'].tolist()\n",
    "    print(f\"Loaded {len(target_item_ids)} Target Items: {target_item_ids}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading target items: {e}\")\n",
    "    target_item_ids = []\n",
    "\n",
    "# --- Calculation Functions ---\n",
    "\n",
    "# Optimized Execution\n",
    "if df is not None:\n",
    "    print(\"Grouping data by User and Item for fast lookup...\")\n",
    "    # Map: UserId -> Set of MovieIds\n",
    "    user_to_movies = df.groupby('userId')['movieId'].apply(set)\n",
    "    # Map: MovieId -> Set of UserIds\n",
    "    movie_to_users = df.groupby('movieId')['userId'].apply(set)\n",
    "    \n",
    "    # 1. Target Users Analysis\n",
    "    for uid in target_user_ids:\n",
    "        if uid not in user_to_movies:\n",
    "            print(f\"User {uid} not found in ratings.\")\n",
    "            continue\n",
    "            \n",
    "        target_movies = user_to_movies[uid]\n",
    "        results = []\n",
    "        \n",
    "        for other_uid, other_movies in user_to_movies.items():\n",
    "            if other_uid == uid: continue\n",
    "            \n",
    "            # Overlap\n",
    "            overlap = len(target_movies.intersection(other_movies))\n",
    "            if overlap > 0:\n",
    "                results.append({'target_user': uid, 'other_user': other_uid, 'No_common_users': overlap})\n",
    "        \n",
    "        # Save\n",
    "        res_df = pd.DataFrame(results).sort_values(by='No_common_users', ascending=False)\n",
    "        save_csv(res_df, f'Target_User_{uid}_Overlap')\n",
    "        print(f\"Saved overlap stats for User {uid} ({len(res_df)} neighbors)\")\n",
    "\n",
    "    # 2. Target Items Analysis\n",
    "    for iid in target_item_ids:\n",
    "        if iid not in movie_to_users:\n",
    "            print(f\"Item {iid} not found in ratings.\")\n",
    "            continue\n",
    "            \n",
    "        target_users = movie_to_users[iid]\n",
    "        results = []\n",
    "        \n",
    "        for other_iid, other_users in movie_to_users.items():\n",
    "            if other_iid == iid: continue\n",
    "            \n",
    "            # Overlap\n",
    "            overlap = len(target_users.intersection(other_users))\n",
    "            if overlap > 0:\n",
    "                results.append({'target_item': iid, 'other_item': other_iid, 'No_coRated_items': overlap})\n",
    "                \n",
    "        # Save\n",
    "        res_df = pd.DataFrame(results).sort_values(by='No_coRated_items', ascending=False)\n",
    "        save_csv(res_df, f'Target_Item_{iid}_Overlap')\n",
    "        print(f\"Saved overlap stats for Item {iid} ({len(res_df)} related items)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63312578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"--- Starting Cold User Extraction ---\")\n",
    "    \n",
    "    # 1. Define Paths and Constants\n",
    "    # stats_per_user.csv is in results/tables\n",
    "    input_path = os.path.join('..', 'results', 'tables', 'stats_per_user.csv')\n",
    "    \n",
    "    TOTAL_ITEMS = 26744  # Constant from project metadata\n",
    "    THRESHOLD_PCT = 2.0  # Cold user threshold <= 2%\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Could not find input file: {input_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Data\n",
    "    print(\"Loading user stats...\")\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"  Total Users Loaded: {len(df)}\")\n",
    "\n",
    "    # 3. Calculate Percentage\n",
    "    # Formula: (Count / Total_Items) * 100\n",
    "    df['pct_rated'] = (df['rating_count_per_user'] / TOTAL_ITEMS) * 100\n",
    "\n",
    "    # 4. Filter Cold Users\n",
    "    print(f\"Filtering for users with <= {THRESHOLD_PCT}% ratings ({int(TOTAL_ITEMS * THRESHOLD_PCT / 100)} items)...\")\n",
    "    cold_users_df = df[df['pct_rated'] <= THRESHOLD_PCT].copy()\n",
    "    \n",
    "    count = len(cold_users_df)\n",
    "    print(f\"  Cold Users Found: {count} ({count/len(df)*100:.2f}% of total)\")\n",
    "\n",
    "    # 5. Save Results\n",
    "    # We want to save to results/tables/cold_user.csv\n",
    "    # utils.save_csv logic: it saves to results/tables/filename.csv relative to where it thinks 'results' is.\n",
    "    # We'll just use save_csv from utils. It handles the 'results' folder discovery.\n",
    "    # Note: 'cold_user' requested filename.\n",
    "    \n",
    "    save_csv(cold_users_df, 'cold_user')\n",
    "    \n",
    "    print(\"--- Extraction Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"--- Starting Medium User Extraction ---\")\n",
    "    \n",
    "    # 1. Define Paths and Constants\n",
    "    input_path = os.path.join('..', 'results', 'tables', 'stats_per_user.csv')\n",
    "    \n",
    "    TOTAL_ITEMS = 26744\n",
    "    MIN_PCT = 2.0\n",
    "    MAX_PCT = 5.0\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Could not find input file: {input_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Data\n",
    "    print(\"Loading user stats...\")\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # 3. Calculate Percentage\n",
    "    df['pct_rated'] = (df['rating_count_per_user'] / TOTAL_ITEMS) * 100\n",
    "\n",
    "    # 4. Filter Medium Users\n",
    "    print(f\"Filtering for users with {MIN_PCT}% <= ratings <= {MAX_PCT}%...\")\n",
    "    \n",
    "    medium_users_df = df[\n",
    "        (df['pct_rated'] >= MIN_PCT) & \n",
    "        (df['pct_rated'] <= MAX_PCT)\n",
    "    ].copy()\n",
    "    \n",
    "    count = len(medium_users_df)\n",
    "    print(f\"  Medium Users Found: {count} ({count/len(df)*100:.2f}% of total)\")\n",
    "\n",
    "    # 5. Save Results\n",
    "    save_csv(medium_users_df, 'medium_user')\n",
    "    \n",
    "    print(\"--- Extraction Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121526f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"--- Starting Rich User Extraction ---\")\n",
    "    \n",
    "    # 1. Define Paths and Constants\n",
    "    input_path = os.path.join('..', 'results', 'tables', 'stats_per_user.csv')\n",
    "    \n",
    "    TOTAL_ITEMS = 26744\n",
    "    THRESHOLD_PCT = 10.0  # Rich user threshold > 10%\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Could not find input file: {input_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Data\n",
    "    print(\"Loading user stats...\")\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # 3. Calculate Percentage\n",
    "    df['pct_rated'] = (df['rating_count_per_user'] / TOTAL_ITEMS) * 100\n",
    "\n",
    "    # 4. Filter Rich Users\n",
    "    print(f\"Filtering for users with > {THRESHOLD_PCT}% ratings...\")\n",
    "    \n",
    "    rich_users_df = df[df['pct_rated'] > THRESHOLD_PCT].copy()\n",
    "    \n",
    "    count = len(rich_users_df)\n",
    "    print(f\"  Rich Users Found: {count} ({count/len(df)*100:.2f}% of total)\")\n",
    "\n",
    "    # 5. Save Results\n",
    "    save_csv(rich_users_df, 'rich_user')\n",
    "    \n",
    "    print(\"--- Extraction Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"--- Starting Item Popularity Extraction ---\")\n",
    "    \n",
    "    # 1. Define Paths and Constants\n",
    "    input_path = os.path.join('..', 'results', 'tables', 'stats_per_item.csv')\n",
    "    \n",
    "    TOTAL_USERS = 138493  # Constant from project metadata\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Could not find input file: {input_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Load Data\n",
    "    print(\"Loading item stats...\")\n",
    "    df = pd.read_csv(input_path)\n",
    "    total_items = len(df)\n",
    "\n",
    "    # 3. Calculate Percentage\n",
    "    # Formula: (Rating_Count / Total_Users) * 100\n",
    "    df['pct_rated'] = (df['rating_count_per_movie'] / TOTAL_USERS) * 100\n",
    "\n",
    "    # 4. Categorize Items\n",
    "    print(\"Categorizing items...\")\n",
    "    \n",
    "    # Low Popularity: <= 2%\n",
    "    low_pop_df = df[df['pct_rated'] <= 2.0].copy()\n",
    "    print(f\"  Low Popularity Items (<= 2%): {len(low_pop_df)} ({len(low_pop_df)/total_items*100:.2f}%)\")\n",
    "    \n",
    "    # Medium Popularity: 2% < x <= 5%\n",
    "    med_pop_df = df[\n",
    "        (df['pct_rated'] > 2.0) & \n",
    "        (df['pct_rated'] <= 5.0)\n",
    "    ].copy()\n",
    "    print(f\"  Medium Popularity Items (2% < x <= 5%): {len(med_pop_df)} ({len(med_pop_df)/total_items*100:.2f}%)\")\n",
    "    \n",
    "    # High Popularity: > 5%\n",
    "    high_pop_df = df[df['pct_rated'] > 5.0].copy()\n",
    "    print(f\"  High Popularity Items (> 5%): {len(high_pop_df)} ({len(high_pop_df)/total_items*100:.2f}%)\")\n",
    "\n",
    "    # 5. Save Results\n",
    "    save_csv(low_pop_df, 'low_popularity_items')\n",
    "    save_csv(med_pop_df, 'medium_popularity_items')\n",
    "    save_csv(high_pop_df, 'high_popularity_items')\n",
    "    \n",
    "    print(\"--- Extraction Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
